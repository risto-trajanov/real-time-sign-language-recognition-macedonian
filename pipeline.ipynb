{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"pipeline.ipynb","provenance":[],"collapsed_sections":["i0QxzyGW1bgA","vIhAQOS71bgC","94Zg04Mk1bgD","5YEpO1n-1bgE","6cZHJpZA1bgH","2xysMHJ4s4s8"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"cells":[{"cell_type":"code","metadata":{"id":"O-dKgimxJCeY"},"source":["#https://medium.com/mlearning-ai/general-approach-for-custom-object-detection-with-tensorflow-2-61593a67a02d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KCAd1qYNtgB4","executionInfo":{"status":"ok","timestamp":1631109528314,"user_tz":-120,"elapsed":804,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["import os\n","import shutil"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qdD0tr0U1vIt","executionInfo":{"status":"ok","timestamp":1631109530015,"user_tz":-120,"elapsed":980,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"5900855b-8cee-485c-ed54-404dba4efd70"},"source":["import tensorflow\n","print(tensorflow.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["2.6.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awaDCB821tnI","executionInfo":{"status":"ok","timestamp":1631109691001,"user_tz":-120,"elapsed":3788,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"32680ef5-2422-4df6-ecdc-7af7fd3d8b44"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"H62an9qW1xri"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpPVXAdo16VW","executionInfo":{"status":"ok","timestamp":1631109722239,"user_tz":-120,"elapsed":687,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"c9ab9c78-42b4-4702-89c9-14674f30edb7"},"source":["%cd .."],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y3jnd030sfmO","executionInfo":{"status":"ok","timestamp":1631109722694,"user_tz":-120,"elapsed":16,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"83de696a-1063-4fda-d1a5-2b08459c4bb6"},"source":["%cd /usr/local/lib/python3.7/dist-packages/tensorflow"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tensorflow\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FOLD59wgslen","executionInfo":{"status":"ok","timestamp":1631109748133,"user_tz":-120,"elapsed":25445,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"31bbf0f4-ccb9-4c38-8588-65cc3a138d5e"},"source":["!git clone https://github.com/tensorflow/models.git"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 61617, done.\u001b[K\n","remote: Counting objects: 100% (61617/61617), done.\u001b[K\n","remote: Compressing objects: 100% (18125/18125), done.\u001b[K\n","remote: Total 61617 (delta 42869), reused 61615 (delta 42867), pack-reused 0\u001b[K\n","Receiving objects: 100% (61617/61617), 574.20 MiB | 29.03 MiB/s, done.\n","Resolving deltas: 100% (42869/42869), done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pN4QOZ87tGqh","executionInfo":{"status":"ok","timestamp":1631109748134,"user_tz":-120,"elapsed":38,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"ff9f192e-3bb3-4b49-ce2d-50b59a737cc2"},"source":["%cd models/research/"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/models/research\n"]}]},{"cell_type":"code","metadata":{"id":"qljg1iZK01ni","executionInfo":{"status":"ok","timestamp":1631109748135,"user_tz":-120,"elapsed":26,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["os.environ['PYTHONPATH'] += f':/usr/local/lib/python3.7/dist-packages/tensorflow/models/'\n","os.environ['PYTHONPATH'] += f':/usr/local/lib/python3.7/dist-packages/tensorflow/models/research/'\n","os.environ['PYTHONPATH'] += f':/usr/local/lib/python3.7/dist-packages/tensorflow/models/research/slim/'\n","os.environ['PYTHONPATH'] += f':/usr/local/lib/python3.7/dist-packages/tensorflow/models/research/object_detection/'"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uCDGLpvX0bob","executionInfo":{"status":"ok","timestamp":1631109752647,"user_tz":-120,"elapsed":4535,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"d1fbe16a-fa48-42d2-a1e7-fdb124e0fabb"},"source":["!pip install tf_slim"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tf_slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 352 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VD6IoPaMtNId","executionInfo":{"status":"ok","timestamp":1631109753074,"user_tz":-120,"elapsed":432,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"55904223-5297-46f8-81e5-2503c85d4611"},"source":["! echo $PYTHONPATH"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/env/python:/usr/local/lib/python3.7/dist-packages/tensorflow/models/:/usr/local/lib/python3.7/dist-packages/tensorflow/models/research/:/usr/local/lib/python3.7/dist-packages/tensorflow/models/research/slim/:/usr/local/lib/python3.7/dist-packages/tensorflow/models/research/object_detection/\n"]}]},{"cell_type":"code","metadata":{"id":"2_lWTz9ytKV6","executionInfo":{"status":"ok","timestamp":1631109753075,"user_tz":-120,"elapsed":8,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["!protoc object_detection/protos/*.proto --python_out=."],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"VGRJ6gkeuEtV","executionInfo":{"status":"ok","timestamp":1631109753076,"user_tz":-120,"elapsed":6,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["!cp object_detection/packages/tf2/setup.py ."],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Zhvq_IJU0Rb","executionInfo":{"status":"ok","timestamp":1631109790207,"user_tz":-120,"elapsed":36547,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"c96ffffd-5712-41af-9679-a3f2bc826fcd"},"source":["!python -m pip install ."],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /usr/local/lib/python3.7/dist-packages/tensorflow/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.32.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n","\u001b[K     |████████████████████████████████| 9.8 MB 8.7 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 23.8 MB/s \n","\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n","\u001b[K     |████████████████████████████████| 211 kB 48.1 MB/s \n","\u001b[?25hCollecting tensorflow-addons\n","  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 47.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 47.6 MB/s \n","\u001b[?25hCollecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n","\u001b[K     |████████████████████████████████| 37.1 MB 47 kB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 9.0 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Collecting tensorflow-text>=2.5.0\n","  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 24.3 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 33.5 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.34.0)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.39.0)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (5.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n","Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.5)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (4.6.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n","Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 700 kB/s \n","\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n","Collecting fastavro<2,>=0.21.4\n","  Downloading fastavro-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 33.1 MB/s \n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 43.7 MB/s \n","\u001b[?25hCollecting avro-python3\n","  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n","Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.0)\n","Collecting orjson<4.0\n","  Downloading orjson-3.6.3-cp37-cp37m-manylinux_2_24_x86_64.whl (234 kB)\n","\u001b[K     |████████████████████████████████| 234 kB 42.5 MB/s \n","\u001b[?25hCollecting future<1.0.0,>=0.18.2\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 37.5 MB/s \n","\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.5.0)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.2.2)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n","Building wheels for collected packages: object-detection, py-cpuinfo, avro-python3, dill, future, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1665159 sha256=1a47efaa50fb541fbe1433ab70761bb9f28e1c9838c7acbfab30a6bcf762de8b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-2t6nt2lt/wheels/c0/29/42/e79b21f860d3b99c7c1f49f1333297a2d951ae8275188f125d\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22258 sha256=9d33be6540a6336a7c89157aa81073a38e5e9ad3a43b6e06119bdad1b91a27c0\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=a97b6e0e6437b5144a1d5ea7cc7e8add97cb5051dc96c0828512121d1fc431bd\n","  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=63fdb7587b77b42dc704f95021d089c4d057e463ab53b4a86c420914acbfdc34\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=5dbfd82a3a247b20808faab353b943dc3726fa652e3e897ae47f3e52cf034463\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=8994a27d276f24cb2cd36f62489e8ddab82d405f7f7904309b9a231f798fce53\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo avro-python3 dill future seqeval\n","Installing collected packages: requests, portalocker, future, dill, colorama, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, orjson, opencv-python-headless, hdfs, fastavro, avro-python3, tf-models-official, lvis, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed apache-beam-2.32.0 avro-python3-1.9.2.1 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.4 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.3.56 orjson-3.6.3 portalocker-2.3.2 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.26.0 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.14.0 tensorflow-model-optimization-0.6.0 tensorflow-text-2.6.0 tf-models-official-2.6.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdBjpg4XWmy2","executionInfo":{"status":"ok","timestamp":1631109833570,"user_tz":-120,"elapsed":43395,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"f7289393-c5ad-423e-91ca-397fa7faf2ce"},"source":["!python object_detection/builders/model_builder_tf2_test.py"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-09-08 14:03:16.481203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-08 14:03:17.117524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-08 14:03:17.118765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","Running tests under Python 3.7.11: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2021-09-08 14:03:17.204846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-08 14:03:17.205931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-08 14:03:17.206879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-08 14:03:22.201882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-08 14:03:22.202774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-08 14:03:22.203515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-08 14:03:22.204269: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-09-08 14:03:22.204432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10819 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n","W0908 14:03:22.540294 139963757860736 model_builder.py:1091] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 5.83s\n","I0908 14:03:22.959059 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 5.83s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.63s\n","I0908 14:03:23.586592 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.63s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\n","I0908 14:03:23.935101 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.33s\n","I0908 14:03:24.264766 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.33s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","W0908 14:03:24.267496 139963757860736 mobilenet_v2.py:297] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9412608/9406464 [==============================] - 0s 0us/step\n","9420800/9406464 [==============================] - 0s 0us/step\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.66s\n","I0908 14:03:26.925368 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.66s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0908 14:03:26.926472 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","I0908 14:03:26.953109 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I0908 14:03:26.971310 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I0908 14:03:26.989776 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n","I0908 14:03:27.109783 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n","I0908 14:03:27.228904 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n","I0908 14:03:27.350719 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n","I0908 14:03:27.485744 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n","I0908 14:03:27.605943 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I0908 14:03:27.640779 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0908 14:03:28.003290 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0908 14:03:28.003500 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n","I0908 14:03:28.003628 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n","I0908 14:03:28.006020 139963757860736 efficientnet_model.py:147] round_filter input=32 output=32\n","I0908 14:03:28.029020 139963757860736 efficientnet_model.py:147] round_filter input=32 output=32\n","I0908 14:03:28.029155 139963757860736 efficientnet_model.py:147] round_filter input=16 output=16\n","I0908 14:03:28.098975 139963757860736 efficientnet_model.py:147] round_filter input=16 output=16\n","I0908 14:03:28.099121 139963757860736 efficientnet_model.py:147] round_filter input=24 output=24\n","I0908 14:03:28.287689 139963757860736 efficientnet_model.py:147] round_filter input=24 output=24\n","I0908 14:03:28.287903 139963757860736 efficientnet_model.py:147] round_filter input=40 output=40\n","I0908 14:03:28.480979 139963757860736 efficientnet_model.py:147] round_filter input=40 output=40\n","I0908 14:03:28.481189 139963757860736 efficientnet_model.py:147] round_filter input=80 output=80\n","I0908 14:03:28.759981 139963757860736 efficientnet_model.py:147] round_filter input=80 output=80\n","I0908 14:03:28.760189 139963757860736 efficientnet_model.py:147] round_filter input=112 output=112\n","I0908 14:03:29.026490 139963757860736 efficientnet_model.py:147] round_filter input=112 output=112\n","I0908 14:03:29.026790 139963757860736 efficientnet_model.py:147] round_filter input=192 output=192\n","I0908 14:03:29.411929 139963757860736 efficientnet_model.py:147] round_filter input=192 output=192\n","I0908 14:03:29.412140 139963757860736 efficientnet_model.py:147] round_filter input=320 output=320\n","I0908 14:03:29.501101 139963757860736 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0908 14:03:29.537524 139963757860736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:03:29.605317 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0908 14:03:29.605468 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n","I0908 14:03:29.605595 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n","I0908 14:03:29.607534 139963757860736 efficientnet_model.py:147] round_filter input=32 output=32\n","I0908 14:03:29.628161 139963757860736 efficientnet_model.py:147] round_filter input=32 output=32\n","I0908 14:03:29.628297 139963757860736 efficientnet_model.py:147] round_filter input=16 output=16\n","I0908 14:03:29.779106 139963757860736 efficientnet_model.py:147] round_filter input=16 output=16\n","I0908 14:03:29.779309 139963757860736 efficientnet_model.py:147] round_filter input=24 output=24\n","I0908 14:03:30.057749 139963757860736 efficientnet_model.py:147] round_filter input=24 output=24\n","I0908 14:03:30.057973 139963757860736 efficientnet_model.py:147] round_filter input=40 output=40\n","I0908 14:03:30.349066 139963757860736 efficientnet_model.py:147] round_filter input=40 output=40\n","I0908 14:03:30.349275 139963757860736 efficientnet_model.py:147] round_filter input=80 output=80\n","I0908 14:03:30.723885 139963757860736 efficientnet_model.py:147] round_filter input=80 output=80\n","I0908 14:03:30.724085 139963757860736 efficientnet_model.py:147] round_filter input=112 output=112\n","I0908 14:03:31.079537 139963757860736 efficientnet_model.py:147] round_filter input=112 output=112\n","I0908 14:03:31.079787 139963757860736 efficientnet_model.py:147] round_filter input=192 output=192\n","I0908 14:03:31.542220 139963757860736 efficientnet_model.py:147] round_filter input=192 output=192\n","I0908 14:03:31.542440 139963757860736 efficientnet_model.py:147] round_filter input=320 output=320\n","I0908 14:03:31.736486 139963757860736 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0908 14:03:31.775236 139963757860736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:03:31.972088 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0908 14:03:31.972331 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n","I0908 14:03:31.972472 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n","I0908 14:03:31.974374 139963757860736 efficientnet_model.py:147] round_filter input=32 output=32\n","I0908 14:03:31.995970 139963757860736 efficientnet_model.py:147] round_filter input=32 output=32\n","I0908 14:03:31.996117 139963757860736 efficientnet_model.py:147] round_filter input=16 output=16\n","I0908 14:03:32.156544 139963757860736 efficientnet_model.py:147] round_filter input=16 output=16\n","I0908 14:03:32.156799 139963757860736 efficientnet_model.py:147] round_filter input=24 output=24\n","I0908 14:03:32.447225 139963757860736 efficientnet_model.py:147] round_filter input=24 output=24\n","I0908 14:03:32.447415 139963757860736 efficientnet_model.py:147] round_filter input=40 output=48\n","I0908 14:03:32.727328 139963757860736 efficientnet_model.py:147] round_filter input=40 output=48\n","I0908 14:03:32.727512 139963757860736 efficientnet_model.py:147] round_filter input=80 output=88\n","I0908 14:03:33.098630 139963757860736 efficientnet_model.py:147] round_filter input=80 output=88\n","I0908 14:03:33.098843 139963757860736 efficientnet_model.py:147] round_filter input=112 output=120\n","I0908 14:03:33.474848 139963757860736 efficientnet_model.py:147] round_filter input=112 output=120\n","I0908 14:03:33.475067 139963757860736 efficientnet_model.py:147] round_filter input=192 output=208\n","I0908 14:03:33.932958 139963757860736 efficientnet_model.py:147] round_filter input=192 output=208\n","I0908 14:03:33.933154 139963757860736 efficientnet_model.py:147] round_filter input=320 output=352\n","I0908 14:03:34.109467 139963757860736 efficientnet_model.py:147] round_filter input=1280 output=1408\n","I0908 14:03:34.141603 139963757860736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:03:34.217486 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0908 14:03:34.217704 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n","I0908 14:03:34.217813 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n","I0908 14:03:34.219721 139963757860736 efficientnet_model.py:147] round_filter input=32 output=40\n","I0908 14:03:34.238760 139963757860736 efficientnet_model.py:147] round_filter input=32 output=40\n","I0908 14:03:34.238900 139963757860736 efficientnet_model.py:147] round_filter input=16 output=24\n","I0908 14:03:34.381157 139963757860736 efficientnet_model.py:147] round_filter input=16 output=24\n","I0908 14:03:34.381332 139963757860736 efficientnet_model.py:147] round_filter input=24 output=32\n","I0908 14:03:34.651901 139963757860736 efficientnet_model.py:147] round_filter input=24 output=32\n","I0908 14:03:34.652102 139963757860736 efficientnet_model.py:147] round_filter input=40 output=48\n","I0908 14:03:34.931266 139963757860736 efficientnet_model.py:147] round_filter input=40 output=48\n","I0908 14:03:34.931476 139963757860736 efficientnet_model.py:147] round_filter input=80 output=96\n","I0908 14:03:35.394649 139963757860736 efficientnet_model.py:147] round_filter input=80 output=96\n","I0908 14:03:35.394898 139963757860736 efficientnet_model.py:147] round_filter input=112 output=136\n","I0908 14:03:35.871395 139963757860736 efficientnet_model.py:147] round_filter input=112 output=136\n","I0908 14:03:35.871604 139963757860736 efficientnet_model.py:147] round_filter input=192 output=232\n","I0908 14:03:36.455993 139963757860736 efficientnet_model.py:147] round_filter input=192 output=232\n","I0908 14:03:36.456185 139963757860736 efficientnet_model.py:147] round_filter input=320 output=384\n","I0908 14:03:36.641374 139963757860736 efficientnet_model.py:147] round_filter input=1280 output=1536\n","I0908 14:03:36.676009 139963757860736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:03:36.996011 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0908 14:03:36.996202 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n","I0908 14:03:36.996310 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0908 14:03:36.998206 139963757860736 efficientnet_model.py:147] round_filter input=32 output=48\n","I0908 14:03:37.017030 139963757860736 efficientnet_model.py:147] round_filter input=32 output=48\n","I0908 14:03:37.017158 139963757860736 efficientnet_model.py:147] round_filter input=16 output=24\n","I0908 14:03:37.161734 139963757860736 efficientnet_model.py:147] round_filter input=16 output=24\n","I0908 14:03:37.161922 139963757860736 efficientnet_model.py:147] round_filter input=24 output=32\n","I0908 14:03:37.549386 139963757860736 efficientnet_model.py:147] round_filter input=24 output=32\n","I0908 14:03:37.549674 139963757860736 efficientnet_model.py:147] round_filter input=40 output=56\n","I0908 14:03:37.918335 139963757860736 efficientnet_model.py:147] round_filter input=40 output=56\n","I0908 14:03:37.918576 139963757860736 efficientnet_model.py:147] round_filter input=80 output=112\n","I0908 14:03:38.481405 139963757860736 efficientnet_model.py:147] round_filter input=80 output=112\n","I0908 14:03:38.481641 139963757860736 efficientnet_model.py:147] round_filter input=112 output=160\n","I0908 14:03:39.088301 139963757860736 efficientnet_model.py:147] round_filter input=112 output=160\n","I0908 14:03:39.088514 139963757860736 efficientnet_model.py:147] round_filter input=192 output=272\n","I0908 14:03:39.833516 139963757860736 efficientnet_model.py:147] round_filter input=192 output=272\n","I0908 14:03:39.833758 139963757860736 efficientnet_model.py:147] round_filter input=320 output=448\n","I0908 14:03:40.011130 139963757860736 efficientnet_model.py:147] round_filter input=1280 output=1792\n","I0908 14:03:40.045225 139963757860736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:03:40.139636 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0908 14:03:40.139826 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n","I0908 14:03:40.139932 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0908 14:03:40.141987 139963757860736 efficientnet_model.py:147] round_filter input=32 output=48\n","I0908 14:03:40.159636 139963757860736 efficientnet_model.py:147] round_filter input=32 output=48\n","I0908 14:03:40.159777 139963757860736 efficientnet_model.py:147] round_filter input=16 output=24\n","I0908 14:03:40.376138 139963757860736 efficientnet_model.py:147] round_filter input=16 output=24\n","I0908 14:03:40.376336 139963757860736 efficientnet_model.py:147] round_filter input=24 output=40\n","I0908 14:03:40.847868 139963757860736 efficientnet_model.py:147] round_filter input=24 output=40\n","I0908 14:03:40.848058 139963757860736 efficientnet_model.py:147] round_filter input=40 output=64\n","I0908 14:03:41.313301 139963757860736 efficientnet_model.py:147] round_filter input=40 output=64\n","I0908 14:03:41.313505 139963757860736 efficientnet_model.py:147] round_filter input=80 output=128\n","I0908 14:03:41.963580 139963757860736 efficientnet_model.py:147] round_filter input=80 output=128\n","I0908 14:03:41.963793 139963757860736 efficientnet_model.py:147] round_filter input=112 output=176\n","I0908 14:03:42.885569 139963757860736 efficientnet_model.py:147] round_filter input=112 output=176\n","I0908 14:03:42.885798 139963757860736 efficientnet_model.py:147] round_filter input=192 output=304\n","I0908 14:03:43.733512 139963757860736 efficientnet_model.py:147] round_filter input=192 output=304\n","I0908 14:03:43.733740 139963757860736 efficientnet_model.py:147] round_filter input=320 output=512\n","I0908 14:03:44.021523 139963757860736 efficientnet_model.py:147] round_filter input=1280 output=2048\n","I0908 14:03:44.060483 139963757860736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:03:44.161084 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0908 14:03:44.161262 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0908 14:03:44.161394 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0908 14:03:44.163600 139963757860736 efficientnet_model.py:147] round_filter input=32 output=56\n","I0908 14:03:44.182844 139963757860736 efficientnet_model.py:147] round_filter input=32 output=56\n","I0908 14:03:44.182986 139963757860736 efficientnet_model.py:147] round_filter input=16 output=32\n","I0908 14:03:44.413991 139963757860736 efficientnet_model.py:147] round_filter input=16 output=32\n","I0908 14:03:44.414220 139963757860736 efficientnet_model.py:147] round_filter input=24 output=40\n","I0908 14:03:44.994995 139963757860736 efficientnet_model.py:147] round_filter input=24 output=40\n","I0908 14:03:44.995195 139963757860736 efficientnet_model.py:147] round_filter input=40 output=72\n","I0908 14:03:45.561739 139963757860736 efficientnet_model.py:147] round_filter input=40 output=72\n","I0908 14:03:45.561950 139963757860736 efficientnet_model.py:147] round_filter input=80 output=144\n","I0908 14:03:46.344289 139963757860736 efficientnet_model.py:147] round_filter input=80 output=144\n","I0908 14:03:46.344490 139963757860736 efficientnet_model.py:147] round_filter input=112 output=200\n","I0908 14:03:47.088625 139963757860736 efficientnet_model.py:147] round_filter input=112 output=200\n","I0908 14:03:47.088824 139963757860736 efficientnet_model.py:147] round_filter input=192 output=344\n","I0908 14:03:48.304224 139963757860736 efficientnet_model.py:147] round_filter input=192 output=344\n","I0908 14:03:48.304423 139963757860736 efficientnet_model.py:147] round_filter input=320 output=576\n","I0908 14:03:48.581836 139963757860736 efficientnet_model.py:147] round_filter input=1280 output=2304\n","I0908 14:03:48.615190 139963757860736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:03:48.732356 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0908 14:03:48.732537 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0908 14:03:48.732660 139963757860736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0908 14:03:48.734555 139963757860736 efficientnet_model.py:147] round_filter input=32 output=64\n","I0908 14:03:48.752321 139963757860736 efficientnet_model.py:147] round_filter input=32 output=64\n","I0908 14:03:48.752486 139963757860736 efficientnet_model.py:147] round_filter input=16 output=32\n","I0908 14:03:49.071078 139963757860736 efficientnet_model.py:147] round_filter input=16 output=32\n","I0908 14:03:49.071269 139963757860736 efficientnet_model.py:147] round_filter input=24 output=48\n","I0908 14:03:49.726637 139963757860736 efficientnet_model.py:147] round_filter input=24 output=48\n","I0908 14:03:49.726881 139963757860736 efficientnet_model.py:147] round_filter input=40 output=80\n","I0908 14:03:50.407890 139963757860736 efficientnet_model.py:147] round_filter input=40 output=80\n","I0908 14:03:50.408086 139963757860736 efficientnet_model.py:147] round_filter input=80 output=160\n","I0908 14:03:51.356975 139963757860736 efficientnet_model.py:147] round_filter input=80 output=160\n","I0908 14:03:51.357197 139963757860736 efficientnet_model.py:147] round_filter input=112 output=224\n","I0908 14:03:52.305907 139963757860736 efficientnet_model.py:147] round_filter input=112 output=224\n","I0908 14:03:52.306170 139963757860736 efficientnet_model.py:147] round_filter input=192 output=384\n","I0908 14:03:53.502360 139963757860736 efficientnet_model.py:147] round_filter input=192 output=384\n","I0908 14:03:53.502579 139963757860736 efficientnet_model.py:147] round_filter input=320 output=640\n","I0908 14:03:54.164506 139963757860736 efficientnet_model.py:147] round_filter input=1280 output=2560\n","I0908 14:03:54.200484 139963757860736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.71s\n","I0908 14:03:54.353448 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.71s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0908 14:03:54.361166 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0908 14:03:54.363254 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0908 14:03:54.363938 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0908 14:03:54.365885 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0908 14:03:54.367733 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0908 14:03:54.368412 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0908 14:03:54.369684 139963757860736 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 37.243s\n","\n","OK (skipped=1)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9m0UJnHU-hm_","executionInfo":{"status":"ok","timestamp":1631109833571,"user_tz":-120,"elapsed":33,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"d4a54605-465d-4696-9244-122d9ba30f10"},"source":["%cd .."],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/models\n"]}]},{"cell_type":"code","metadata":{"id":"EgCwyKjY-kE4","executionInfo":{"status":"ok","timestamp":1631109833572,"user_tz":-120,"elapsed":21,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["os.makedirs('annotations/xmls/train', exist_ok=True)\n","os.makedirs('annotations/xmls/test', exist_ok=True)\n","os.makedirs('images/train', exist_ok=True)\n","os.makedirs('images/test', exist_ok=True)\n","os.makedirs('checkpoints', exist_ok=True)\n","os.makedirs('tf_record', exist_ok=True)\n","os.makedirs('scripts', exist_ok=True)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gs2JfFtPtQwZ","executionInfo":{"status":"ok","timestamp":1631109838748,"user_tz":-120,"elapsed":5186,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"aa1e9237-f983-4aed-d53b-0a768d289acc"},"source":["!pip install lvis"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (0.5.3)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n","Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.1)\n","Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.24)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.10.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.2)\n","Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.4.7)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ma2PgeM5teWp","executionInfo":{"status":"ok","timestamp":1631109840220,"user_tz":-120,"elapsed":1497,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"6571b343-65a2-46e8-f02e-a979916fbb7b"},"source":["!pip install tensorflow-addons"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.14.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"]}]},{"cell_type":"code","metadata":{"id":"hXpB-qxEx6tU","executionInfo":{"status":"ok","timestamp":1631110804323,"user_tz":-120,"elapsed":262,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["import os\n","import glob\n","import pandas as pd\n","import xml.etree.ElementTree as ET\n","\n","\n","def xml_to_csv(path):\n","    xml_list = []\n","    for xml_file in glob.glob(path + '/*.xml'):\n","        tree = ET.parse(xml_file)\n","        root = tree.getroot()\n","        for member in root.findall('object'):\n","            value = (root.find('filename').text,\n","                     int(root.find('size')[0].text),\n","                     int(root.find('size')[1].text),\n","                     member[0].text,\n","                     int(member[4][0].text),\n","                     int(member[4][1].text),\n","                     int(member[4][2].text),\n","                     int(member[4][3].text)\n","                     )\n","            xml_list.append(value)\n","    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","    xml_df = pd.DataFrame(xml_list, columns=column_name)\n","    return xml_df\n"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i0QxzyGW1bgA"},"source":["# 0. Setup Paths"]},{"cell_type":"code","metadata":{"id":"kVfqbxZ8AUG5","executionInfo":{"status":"ok","timestamp":1631109840222,"user_tz":-120,"elapsed":11,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["root = '/content/drive/My Drive/Fax/FINKI/Semestar-8/IIS/Project/real-time-sign-language-recognition-macedonian/'"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"kkYkYVG81bgB","executionInfo":{"status":"ok","timestamp":1631109888303,"user_tz":-120,"elapsed":272,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["WORKSPACE_PATH = f'{root}/workspace'\n","SCRIPTS_PATH = f'{root}/scripts'\n","ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n","IMAGE_PATH = WORKSPACE_PATH+'/images'"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vIhAQOS71bgC"},"source":["# 1. Create Label Map"]},{"cell_type":"code","metadata":{"id":"kwsE4D2v4LRm","executionInfo":{"status":"ok","timestamp":1631109892634,"user_tz":-120,"elapsed":353,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["labels = [{'name':'a', 'id':1}, {'name':'b', 'id':2}]"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"SfCdm8S31bgC","executionInfo":{"status":"ok","timestamp":1631110662924,"user_tz":-120,"elapsed":435,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["with open('./annotations' + '/label_map.pbtxt', 'w') as f:\n","    for label in labels:\n","        f.write('item { \\n')\n","        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n","        f.write('\\tid:{}\\n'.format(label['id']))\n","        f.write('}\\n')"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"KPFRNX8ByTDs","executionInfo":{"status":"ok","timestamp":1631110943661,"user_tz":-120,"elapsed":670,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["%cp ./annotations/label_map.pbtxt '/content/drive/My Drive/Fax/FINKI/Semestar-8/IIS/Project/real-time-sign-language-recognition-macedonian/workspace/annotations'"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"id":"2M4bLjSZ_Brr","executionInfo":{"status":"ok","timestamp":1631110724835,"user_tz":-120,"elapsed":3041,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["images = os.listdir(IMAGE_PATH + '/colectedimages')\n","annotations = os.listdir(ANNOTATION_PATH)\n","scripts = os.listdir(SCRIPTS_PATH)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"noi-S_ikAKvJ","executionInfo":{"status":"ok","timestamp":1631110737565,"user_tz":-120,"elapsed":11415,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["for img in images:\n","  if img.endswith('.png') or img.endswith('.jpg'):\n","    shutil.copyfile(IMAGE_PATH + '/colectedimages/' + img, './images/' + img)\n","  \n","  if img.endswith('.xml'):\n","    shutil.copyfile(IMAGE_PATH + '/colectedimages/' + img, './annotations/xmls/' + img)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"FOE1dWCcQisx","executionInfo":{"status":"ok","timestamp":1631110737575,"user_tz":-120,"elapsed":17,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["train_images = os.listdir(f'{IMAGE_PATH}/train/')"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"sp2r2_1jRnIa","executionInfo":{"status":"ok","timestamp":1631110737576,"user_tz":-120,"elapsed":15,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["train_images_names = [name.replace('.png', '').replace('.jpg', '') for name in train_images if name.endswith('.png') or name.endswith('.jpg')]"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"rIA3SyMwQg3a","executionInfo":{"status":"ok","timestamp":1631110744237,"user_tz":-120,"elapsed":6674,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["for img in train_images:\n","  if img.endswith('.png') or img.endswith('.jpg'):\n","    shutil.copyfile(IMAGE_PATH + '/train/' + img, './images/train/' + img)\n","  \n","  if img.endswith('.xml'):\n","    shutil.copyfile(IMAGE_PATH + '/train/' + img, './annotations/xmls/train/' + img)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0HfjBZzRQa3","executionInfo":{"status":"ok","timestamp":1631110744238,"user_tz":-120,"elapsed":8,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["test_images = os.listdir(f'{IMAGE_PATH}/test/')"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVIwx0t1SH9P","executionInfo":{"status":"ok","timestamp":1631110744239,"user_tz":-120,"elapsed":8,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["test_images_names = [name.replace('.png', '').replace('.jpg', '') for name in test_images if name.endswith('.png') or name.endswith('.jpg')]"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"hk51VwvYRTDh","executionInfo":{"status":"ok","timestamp":1631110746219,"user_tz":-120,"elapsed":1987,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["for img in test_images:\n","  if img.endswith('.png') or img.endswith('.jpg'):\n","    shutil.copyfile(IMAGE_PATH + '/test/' + img, './images/test/' + img)\n","  \n","  if img.endswith('.xml'):\n","    shutil.copyfile(IMAGE_PATH + '/test/' + img, './annotations/xmls/test/' + img)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"uI3WWlIaGpz5","executionInfo":{"status":"ok","timestamp":1631110746223,"user_tz":-120,"elapsed":10,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["images = os.listdir('./images')"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ylytag-mGm2M","executionInfo":{"status":"ok","timestamp":1631110746224,"user_tz":-120,"elapsed":7,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["with open('./annotations' + '/trainval.txt', 'w') as f:\n","    for img in images:\n","      img_name = img.replace('.png', '')\n","      img_name = img_name.replace('.jpg', '') \n","      f.write(f'{img_name}\\n')"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"4IazzWg0KrSs","executionInfo":{"status":"ok","timestamp":1631110747178,"user_tz":-120,"elapsed":960,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["for script in scripts:\n","  if script.endswith('.py'):\n","    shutil.copyfile(SCRIPTS_PATH + '/' + script, './scripts/' + script)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"YYBj_IMLO6dX","executionInfo":{"status":"ok","timestamp":1631110747184,"user_tz":-120,"elapsed":14,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["csv_from_xml_df = xml_to_csv('./annotations/xmls')"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rk-_QTrqPAZu","executionInfo":{"status":"ok","timestamp":1631110747186,"user_tz":-120,"elapsed":13,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["csv_from_xml_df.to_csv('./annotations/csv_from_xml.csv')"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"_YBrm6VESMnm","executionInfo":{"status":"ok","timestamp":1631110747187,"user_tz":-120,"elapsed":14,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["train_csv = csv_from_xml_df[csv_from_xml_df['filename'].isin(train_images_names)]"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"PucrIoheTMMt","executionInfo":{"status":"ok","timestamp":1631110747189,"user_tz":-120,"elapsed":15,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["train_csv.to_csv('train_csv.csv')"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"SH96oG4zTDMN","executionInfo":{"status":"ok","timestamp":1631110747190,"user_tz":-120,"elapsed":15,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["test_csv = csv_from_xml_df[csv_from_xml_df['filename'].isin(test_images_names)]"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"eMOk7jQHTQAS","executionInfo":{"status":"ok","timestamp":1631110750677,"user_tz":-120,"elapsed":296,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["test_csv.to_csv('test_csv.csv')"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"94Zg04Mk1bgD"},"source":["# 2. Create TF records"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E03gmSzq1bgD","executionInfo":{"status":"ok","timestamp":1631110825161,"user_tz":-120,"elapsed":7067,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"1414d279-9d6d-4feb-f333-14760b006d8f"},"source":["!python {'./scripts/generate_tfrecord.py'} -x{'./annotations/xmls/train'} -i{'./images/train'} -l {'./annotations/label_map.pbtxt'} -o {'tf_record/train.record'}\n","!python {'./scripts/generate_tfrecord.py'} -x{'./annotations/xmls/test'} -i{'./images/test'} -l {'./annotations/label_map.pbtxt'} -o {'tf_record/test.record'}"],"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully created the TFRecord file: tf_record/train.record\n","Successfully created the TFRecord file: tf_record/test.record\n"]}]},{"cell_type":"markdown","metadata":{"id":"5YEpO1n-1bgE"},"source":["# 3. Download TF Models Pretrained Models from Tensorflow Model Zoo"]},{"cell_type":"code","metadata":{"id":"SCos8Zl3k9iE","executionInfo":{"status":"ok","timestamp":1631110828560,"user_tz":-120,"elapsed":261,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["pretrained_model = 'ssd_mobilenet_v2_320x320_coco17_tpu-8'"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"4l6U-n8Rj-l_","executionInfo":{"status":"ok","timestamp":1631110828806,"user_tz":-120,"elapsed":18,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"670b1a95-9951-4a57-94a5-4a4a09e3b594"},"source":["%pwd"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/usr/local/lib/python3.7/dist-packages/tensorflow/models'"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"4Mk2H1lTkAZh","executionInfo":{"status":"ok","timestamp":1631110828808,"user_tz":-120,"elapsed":15,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["os.makedirs('./pretrained_model', exist_ok = True)"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kUMMVYWVkIAb","executionInfo":{"status":"ok","timestamp":1631110833134,"user_tz":-120,"elapsed":4339,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"a3a53c8e-f92b-485a-e737-ee9a68f680fb"},"source":["%cd pretrained_model/\n","!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n","!tar -zxf ssd_mobilenet_v2_coco_2018_03_29.tar.gz"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/models/pretrained_model\n","--2021-09-08 14:20:28--  http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 172.253.119.128, 2607:f8b0:4001:c23::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|172.253.119.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 187925923 (179M) [application/x-tar]\n","Saving to: ‘ssd_mobilenet_v2_coco_2018_03_29.tar.gz’\n","\n","ssd_mobilenet_v2_co 100%[===================>] 179.22M   161MB/s    in 1.1s    \n","\n","2021-09-08 14:20:29 (161 MB/s) - ‘ssd_mobilenet_v2_coco_2018_03_29.tar.gz’ saved [187925923/187925923]\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x3CgP9Vw3Oo-","executionInfo":{"status":"ok","timestamp":1631110834428,"user_tz":-120,"elapsed":1306,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"dbf42be5-fd42-443c-debc-f738ad4931fc"},"source":["!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n","!tar -zxf ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz"],"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-09-08 14:20:32--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 172.253.119.128, 2607:f8b0:4001:c23::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|172.253.119.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 46042990 (44M) [application/x-tar]\n","Saving to: ‘ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz’\n","\n","ssd_mobilenet_v2_32 100%[===================>]  43.91M   130MB/s    in 0.3s    \n","\n","2021-09-08 14:20:33 (130 MB/s) - ‘ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz’ saved [46042990/46042990]\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5REitQYDkNEY","executionInfo":{"status":"ok","timestamp":1631110834429,"user_tz":-120,"elapsed":26,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"3d37b4a4-b0a6-44ff-b692-a5133974a401"},"source":["%cd .."],"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/models\n"]}]},{"cell_type":"code","metadata":{"id":"iS4TI5mwkmLt","executionInfo":{"status":"ok","timestamp":1631110834430,"user_tz":-120,"elapsed":23,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["checkpoint_files_1 = ['model.ckpt.meta', 'model.ckpt.index', 'model.ckpt.data-00000-of-00001']\n","checkpoint_files_2 = ['checkpoint', 'ckpt-0.data-00000-of-00001', 'ckpt-0.index']"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"e2qJqIYZkweO","executionInfo":{"status":"ok","timestamp":1631110834431,"user_tz":-120,"elapsed":22,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["for file in checkpoint_files_2:\n","  shutil.copyfile('./pretrained_model/' + pretrained_model + '/checkpoint/' + file, './checkpoints/' + file)"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"vVJh1PXDmvht","executionInfo":{"status":"ok","timestamp":1631110834433,"user_tz":-120,"elapsed":22,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"50e4e0b4-6d88-4cdf-f08b-03d94b782e86"},"source":["shutil.copyfile('./pretrained_model/' + pretrained_model + '/pipeline.config', './pipeline.config')"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'./pipeline.config'"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DyayAWCzme_K","executionInfo":{"status":"ok","timestamp":1631110834434,"user_tz":-120,"elapsed":19,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"6151a332-c3c5-4350-9016-5e891e2c77cb"},"source":["print(os.listdir('./checkpoints'))"],"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["['checkpoint', 'ckpt-0.data-00000-of-00001', 'ckpt-0.index']\n"]}]},{"cell_type":"markdown","metadata":{"id":"6cZHJpZA1bgH"},"source":["# 5. Update Config For Transfer Learning"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zb6NWwAKoK6y","executionInfo":{"status":"ok","timestamp":1631110834434,"user_tz":-120,"elapsed":15,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"a8fb8926-b867-4b9c-a657-aaa9944a5342"},"source":["%cd research/"],"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/models/research\n"]}]},{"cell_type":"code","metadata":{"id":"Qbungz8wpFH4","executionInfo":{"status":"ok","timestamp":1631110834825,"user_tz":-120,"elapsed":405,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["import tensorflow as tf\n","from object_detection.utils import config_util\n","from object_detection.protos import pipeline_pb2\n","from google.protobuf import text_format"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Vi2dYRn1bgI","executionInfo":{"status":"ok","timestamp":1631110834827,"user_tz":-120,"elapsed":37,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["CONFIG_PATH = '../pipeline.config'"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"LAZ4Q8U-xl3s","executionInfo":{"status":"ok","timestamp":1631110834829,"user_tz":-120,"elapsed":37,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"d2fdabfb-19d2-4b6c-8e40-1d47cd616272"},"source":["%pwd"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/usr/local/lib/python3.7/dist-packages/tensorflow/models/research'"]},"metadata":{},"execution_count":58}]},{"cell_type":"markdown","metadata":{"id":"X6aNxJGuoj66"},"source":["## For ssd mobilenet v2, you could remove \"batch_norm_trainable: true\" as this field is deprecated now.\n","\n","* Go to /usr/local/lib/python3.7/dist-packages/tensorflow/models/pipeline.config and delete the line batch_norm_trainable "]},{"cell_type":"code","metadata":{"id":"uh4VZdQf1bgI","executionInfo":{"status":"ok","timestamp":1631110834830,"user_tz":-120,"elapsed":34,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"tmIyI8mc1bgI","executionInfo":{"status":"ok","timestamp":1631110834831,"user_tz":-120,"elapsed":34,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n","with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:                                                                                                                                                                                                                     \n","    proto_str = f.read()                                                                                                                                                                                                                                          \n","    text_format.Merge(proto_str, pipeline_config)  "],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"qYOHHpqO9Gdi","executionInfo":{"status":"ok","timestamp":1631110834833,"user_tz":-120,"elapsed":34,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"1c29de2c-8b9b-4d2d-f97f-7ebf7b429ba4"},"source":["%pwd"],"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/usr/local/lib/python3.7/dist-packages/tensorflow/models/research'"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"qnYXk_RM9KGk","executionInfo":{"status":"ok","timestamp":1631110834834,"user_tz":-120,"elapsed":31,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["pwd = '/usr/local/lib/python3.7/dist-packages/tensorflow/models'"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3AFMlz41bgJ","executionInfo":{"status":"ok","timestamp":1631110834835,"user_tz":-120,"elapsed":31,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["pipeline_config.model.ssd.num_classes = 2\n","pipeline_config.train_config.batch_size = 4\n","pipeline_config.model.ssd.feature_extractor.type = \"ssd_mobilenet_v2_keras\"\n","pipeline_config.train_config.fine_tune_checkpoint = f'{pwd}/checkpoints/ckpt-0'\n","pipeline_config.train_config.fine_tune_checkpoint_type = f'detection'\n","pipeline_config.train_config.num_steps = 1500\n","pipeline_config.train_input_reader.label_map_path= f'{pwd}/annotations/label_map.pbtxt'\n","pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [f'{pwd}/tf_record/train.record']\n","pipeline_config.eval_input_reader[0].label_map_path = f'{pwd}/annotations/label_map.pbtxt'\n","pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [f'{pwd}/tf_record/test.record']"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"mXx1OTTD1bgJ","executionInfo":{"status":"ok","timestamp":1631110834835,"user_tz":-120,"elapsed":29,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n","with tf.io.gfile.GFile('../pipeline.config', \"wb\") as f:                                                                                                                                                                                                                     \n","    f.write(config_text)   "],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"IZdKMuV6siwW","executionInfo":{"status":"ok","timestamp":1631110834836,"user_tz":-120,"elapsed":29,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"d4b8d3ab-043a-43b8-b58f-d7470f3e9624"},"source":["%pwd"],"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/usr/local/lib/python3.7/dist-packages/tensorflow/models/research'"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lv4Cv_XskHv","executionInfo":{"status":"ok","timestamp":1631110834837,"user_tz":-120,"elapsed":28,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"9fd8de02-bff8-4d35-9630-cd3c18d3de7d"},"source":["%cd .."],"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/models\n"]}]},{"cell_type":"code","metadata":{"id":"yKObnzLysubv","executionInfo":{"status":"ok","timestamp":1631110834838,"user_tz":-120,"elapsed":27,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["os.makedirs('./train', exist_ok = True)\n","os.makedirs('./test', exist_ok = True)"],"execution_count":67,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2xysMHJ4s4s8"},"source":["# Train"]},{"cell_type":"code","metadata":{"id":"nFAYNQCan-1M"},"source":["%mv ./pretrained_model/ssd_mobilenet_v2_320x320_coco17_tpu-8/checkpoint/ ./pretrained_model/ssd_mobilenet_v2_320x320_coco17_tpu-8/checkpoints/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g2jiWYNvyfRY"},"source":["tf.get_logger().setLevel('ERROR')\n","from absl import logging\n","logging.set_verbosity(logging.ERROR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70N_Jm7Ds6GL","executionInfo":{"status":"ok","timestamp":1630949798843,"user_tz":-120,"elapsed":445121,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"85db04cd-826c-4803-89fe-beb3b2b14d2a"},"source":["!python ./research/object_detection/model_main_tf2.py \\\n","    --train_dir=./train \\\n","    --pipeline_config_path=pipeline.config \\\n","    --model_dir=./train \\\n","    --alsologtostderr"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-09-06 17:29:16.501218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:29:16.511919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:29:16.512758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:29:16.514387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:29:16.515233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:29:16.516091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:29:17.003152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:29:17.004057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:29:17.004912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:29:17.005671: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-09-06 17:29:17.005738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10819 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0906 17:29:17.010820 139734985152384 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: None\n","I0906 17:29:17.015503 139734985152384 config_util.py:552] Maybe overwriting train_steps: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0906 17:29:17.015697 139734985152384 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/models/research/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0906 17:29:17.162340 139734985152384 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/models/research/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/usr/local/lib/python3.7/dist-packages/tensorflow/models/tf_record/train.record']\n","I0906 17:29:17.173945 139734985152384 dataset_builder.py:163] Reading unweighted datasets: ['/usr/local/lib/python3.7/dist-packages/tensorflow/models/tf_record/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/usr/local/lib/python3.7/dist-packages/tensorflow/models/tf_record/train.record']\n","I0906 17:29:17.174203 139734985152384 dataset_builder.py:80] Reading record datasets for input file: ['/usr/local/lib/python3.7/dist-packages/tensorflow/models/tf_record/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0906 17:29:17.174350 139734985152384 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0906 17:29:17.174495 139734985152384 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W0906 17:29:17.186663 139734985152384 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0906 17:29:17.217181 139734985152384 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0906 17:29:25.795870 139734985152384 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0906 17:29:30.115326 139734985152384 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0906 17:29:33.546385 139734985152384 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2021-09-06 17:29:36.328016: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0906 17:29:45.698816 139731711973120 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0906 17:29:45.699281 139731711973120 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0906 17:29:45.699544 139731711973120 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0906 17:29:45.699818 139731711973120 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0906 17:29:45.700208 139731711973120 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0906 17:29:45.700426 139731711973120 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","2021-09-06 17:30:01.758794: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8004\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0906 17:30:29.361505 139734985152384 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0906 17:30:29.362738 139734985152384 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0906 17:30:29.365430 139734985152384 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0906 17:30:29.366518 139734985152384 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0906 17:30:29.369259 139734985152384 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0906 17:30:29.370340 139734985152384 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0906 17:30:29.372964 139734985152384 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0906 17:30:29.374043 139734985152384 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0906 17:30:29.376743 139734985152384 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0906 17:30:29.377789 139734985152384 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0906 17:30:30.086293 139731728758528 deprecation.py:548] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","INFO:tensorflow:Step 100 per-step time 0.591s\n","I0906 17:31:28.752869 139734985152384 model_lib_v2.py:700] Step 100 per-step time 0.591s\n","INFO:tensorflow:{'Loss/classification_loss': 1.0696195,\n"," 'Loss/localization_loss': 0.6208461,\n"," 'Loss/regularization_loss': 0.45073926,\n"," 'Loss/total_loss': 2.1412048,\n"," 'learning_rate': 0.1666635}\n","I0906 17:31:28.753374 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 1.0696195,\n"," 'Loss/localization_loss': 0.6208461,\n"," 'Loss/regularization_loss': 0.45073926,\n"," 'Loss/total_loss': 2.1412048,\n"," 'learning_rate': 0.1666635}\n","INFO:tensorflow:Step 200 per-step time 0.221s\n","I0906 17:31:50.791075 139734985152384 model_lib_v2.py:700] Step 200 per-step time 0.221s\n","INFO:tensorflow:{'Loss/classification_loss': 0.43467376,\n"," 'Loss/localization_loss': 0.6155445,\n"," 'Loss/regularization_loss': 0.46110007,\n"," 'Loss/total_loss': 1.5113183,\n"," 'learning_rate': 0.19999701}\n","I0906 17:31:50.791453 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.43467376,\n"," 'Loss/localization_loss': 0.6155445,\n"," 'Loss/regularization_loss': 0.46110007,\n"," 'Loss/total_loss': 1.5113183,\n"," 'learning_rate': 0.19999701}\n","INFO:tensorflow:Step 300 per-step time 0.218s\n","I0906 17:32:12.632350 139734985152384 model_lib_v2.py:700] Step 300 per-step time 0.218s\n","INFO:tensorflow:{'Loss/classification_loss': 0.54822296,\n"," 'Loss/localization_loss': 0.46255973,\n"," 'Loss/regularization_loss': 0.46760467,\n"," 'Loss/total_loss': 1.4783874,\n"," 'learning_rate': 0.23333052}\n","I0906 17:32:12.632730 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.54822296,\n"," 'Loss/localization_loss': 0.46255973,\n"," 'Loss/regularization_loss': 0.46760467,\n"," 'Loss/total_loss': 1.4783874,\n"," 'learning_rate': 0.23333052}\n","INFO:tensorflow:Step 400 per-step time 0.221s\n","I0906 17:32:34.711570 139734985152384 model_lib_v2.py:700] Step 400 per-step time 0.221s\n","INFO:tensorflow:{'Loss/classification_loss': 0.4955512,\n"," 'Loss/localization_loss': 0.47559926,\n"," 'Loss/regularization_loss': 0.46568188,\n"," 'Loss/total_loss': 1.4368323,\n"," 'learning_rate': 0.26666403}\n","I0906 17:32:34.711933 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.4955512,\n"," 'Loss/localization_loss': 0.47559926,\n"," 'Loss/regularization_loss': 0.46568188,\n"," 'Loss/total_loss': 1.4368323,\n"," 'learning_rate': 0.26666403}\n","INFO:tensorflow:Step 500 per-step time 0.219s\n","I0906 17:32:56.632703 139734985152384 model_lib_v2.py:700] Step 500 per-step time 0.219s\n","INFO:tensorflow:{'Loss/classification_loss': 0.26354566,\n"," 'Loss/localization_loss': 0.40694752,\n"," 'Loss/regularization_loss': 0.48247474,\n"," 'Loss/total_loss': 1.1529679,\n"," 'learning_rate': 0.2999975}\n","I0906 17:32:56.633122 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.26354566,\n"," 'Loss/localization_loss': 0.40694752,\n"," 'Loss/regularization_loss': 0.48247474,\n"," 'Loss/total_loss': 1.1529679,\n"," 'learning_rate': 0.2999975}\n","INFO:tensorflow:Step 600 per-step time 0.219s\n","I0906 17:33:18.489744 139734985152384 model_lib_v2.py:700] Step 600 per-step time 0.219s\n","INFO:tensorflow:{'Loss/classification_loss': 0.38525227,\n"," 'Loss/localization_loss': 0.33884683,\n"," 'Loss/regularization_loss': 0.47918022,\n"," 'Loss/total_loss': 1.2032793,\n"," 'learning_rate': 0.33333102}\n","I0906 17:33:18.490124 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.38525227,\n"," 'Loss/localization_loss': 0.33884683,\n"," 'Loss/regularization_loss': 0.47918022,\n"," 'Loss/total_loss': 1.2032793,\n"," 'learning_rate': 0.33333102}\n","INFO:tensorflow:Step 700 per-step time 0.219s\n","I0906 17:33:40.366260 139734985152384 model_lib_v2.py:700] Step 700 per-step time 0.219s\n","INFO:tensorflow:{'Loss/classification_loss': 0.4409906,\n"," 'Loss/localization_loss': 0.3444106,\n"," 'Loss/regularization_loss': 0.47570854,\n"," 'Loss/total_loss': 1.2611098,\n"," 'learning_rate': 0.36666453}\n","I0906 17:33:40.366604 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.4409906,\n"," 'Loss/localization_loss': 0.3444106,\n"," 'Loss/regularization_loss': 0.47570854,\n"," 'Loss/total_loss': 1.2611098,\n"," 'learning_rate': 0.36666453}\n","INFO:tensorflow:Step 800 per-step time 0.218s\n","I0906 17:34:02.179474 139734985152384 model_lib_v2.py:700] Step 800 per-step time 0.218s\n","INFO:tensorflow:{'Loss/classification_loss': 0.36529192,\n"," 'Loss/localization_loss': 0.35785803,\n"," 'Loss/regularization_loss': 0.46761602,\n"," 'Loss/total_loss': 1.190766,\n"," 'learning_rate': 0.399998}\n","I0906 17:34:02.179857 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.36529192,\n"," 'Loss/localization_loss': 0.35785803,\n"," 'Loss/regularization_loss': 0.46761602,\n"," 'Loss/total_loss': 1.190766,\n"," 'learning_rate': 0.399998}\n","INFO:tensorflow:Step 900 per-step time 0.218s\n","I0906 17:34:24.014745 139734985152384 model_lib_v2.py:700] Step 900 per-step time 0.218s\n","INFO:tensorflow:{'Loss/classification_loss': 0.37315628,\n"," 'Loss/localization_loss': 0.23264499,\n"," 'Loss/regularization_loss': 0.45759338,\n"," 'Loss/total_loss': 1.0633947,\n"," 'learning_rate': 0.4333315}\n","I0906 17:34:24.015216 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.37315628,\n"," 'Loss/localization_loss': 0.23264499,\n"," 'Loss/regularization_loss': 0.45759338,\n"," 'Loss/total_loss': 1.0633947,\n"," 'learning_rate': 0.4333315}\n","INFO:tensorflow:Step 1000 per-step time 0.218s\n","I0906 17:34:45.847497 139734985152384 model_lib_v2.py:700] Step 1000 per-step time 0.218s\n","INFO:tensorflow:{'Loss/classification_loss': 0.26672593,\n"," 'Loss/localization_loss': 0.2694708,\n"," 'Loss/regularization_loss': 0.4456914,\n"," 'Loss/total_loss': 0.9818881,\n"," 'learning_rate': 0.46666503}\n","I0906 17:34:45.847858 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.26672593,\n"," 'Loss/localization_loss': 0.2694708,\n"," 'Loss/regularization_loss': 0.4456914,\n"," 'Loss/total_loss': 0.9818881,\n"," 'learning_rate': 0.46666503}\n","INFO:tensorflow:Step 1100 per-step time 0.225s\n","I0906 17:35:08.312108 139734985152384 model_lib_v2.py:700] Step 1100 per-step time 0.225s\n","INFO:tensorflow:{'Loss/classification_loss': 0.43593702,\n"," 'Loss/localization_loss': 0.21541332,\n"," 'Loss/regularization_loss': 0.43944234,\n"," 'Loss/total_loss': 1.0907927,\n"," 'learning_rate': 0.4999985}\n","I0906 17:35:08.312580 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.43593702,\n"," 'Loss/localization_loss': 0.21541332,\n"," 'Loss/regularization_loss': 0.43944234,\n"," 'Loss/total_loss': 1.0907927,\n"," 'learning_rate': 0.4999985}\n","INFO:tensorflow:Step 1200 per-step time 0.219s\n","I0906 17:35:30.239643 139734985152384 model_lib_v2.py:700] Step 1200 per-step time 0.219s\n","INFO:tensorflow:{'Loss/classification_loss': 0.21319795,\n"," 'Loss/localization_loss': 0.22935697,\n"," 'Loss/regularization_loss': 0.43070433,\n"," 'Loss/total_loss': 0.87325925,\n"," 'learning_rate': 0.53333205}\n","I0906 17:35:30.240002 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.21319795,\n"," 'Loss/localization_loss': 0.22935697,\n"," 'Loss/regularization_loss': 0.43070433,\n"," 'Loss/total_loss': 0.87325925,\n"," 'learning_rate': 0.53333205}\n","INFO:tensorflow:Step 1300 per-step time 0.219s\n","I0906 17:35:52.165372 139734985152384 model_lib_v2.py:700] Step 1300 per-step time 0.219s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2973421,\n"," 'Loss/localization_loss': 0.30603945,\n"," 'Loss/regularization_loss': 0.43738255,\n"," 'Loss/total_loss': 1.0407641,\n"," 'learning_rate': 0.56666553}\n","I0906 17:35:52.165773 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.2973421,\n"," 'Loss/localization_loss': 0.30603945,\n"," 'Loss/regularization_loss': 0.43738255,\n"," 'Loss/total_loss': 1.0407641,\n"," 'learning_rate': 0.56666553}\n","INFO:tensorflow:Step 1400 per-step time 0.217s\n","I0906 17:36:13.908392 139734985152384 model_lib_v2.py:700] Step 1400 per-step time 0.217s\n","INFO:tensorflow:{'Loss/classification_loss': 0.36580122,\n"," 'Loss/localization_loss': 0.21771453,\n"," 'Loss/regularization_loss': 0.42609712,\n"," 'Loss/total_loss': 1.0096129,\n"," 'learning_rate': 0.599999}\n","I0906 17:36:13.908756 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.36580122,\n"," 'Loss/localization_loss': 0.21771453,\n"," 'Loss/regularization_loss': 0.42609712,\n"," 'Loss/total_loss': 1.0096129,\n"," 'learning_rate': 0.599999}\n","INFO:tensorflow:Step 1500 per-step time 0.218s\n","I0906 17:36:35.743010 139734985152384 model_lib_v2.py:700] Step 1500 per-step time 0.218s\n","INFO:tensorflow:{'Loss/classification_loss': 0.27399355,\n"," 'Loss/localization_loss': 0.19843893,\n"," 'Loss/regularization_loss': 0.44529173,\n"," 'Loss/total_loss': 0.91772425,\n"," 'learning_rate': 0.6333325}\n","I0906 17:36:35.743357 139734985152384 model_lib_v2.py:701] {'Loss/classification_loss': 0.27399355,\n"," 'Loss/localization_loss': 0.19843893,\n"," 'Loss/regularization_loss': 0.44529173,\n"," 'Loss/total_loss': 0.91772425,\n"," 'learning_rate': 0.6333325}\n"]}]},{"cell_type":"code","metadata":{"id":"8v2zh-ae8N1H"},"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GQCVEcxb7jaX"},"source":["%tensorboard --logdir=./train/train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k45b44FW_Bf2","executionInfo":{"status":"ok","timestamp":1630949803018,"user_tz":-120,"elapsed":38,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"1d3f63ac-4d9b-4b83-b6c9-c8155f396ac3"},"source":["%rm -r ./fine_tune_model"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove './fine_tune_model': No such file or directory\n"]}]},{"cell_type":"code","metadata":{"id":"w7blPK1k8MoC"},"source":["os.makedirs('./fine_tune_model', exist_ok = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f1C67_Uo_Jub"},"source":["%rm -r '/content/drive/My Drive/Fax/FINKI/Semestar-8/IIS/Project/real-time-sign-language-recognition-macedonian/fine_tune_model/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Az49K0HR_Rp_"},"source":["%rm -r '/content/drive/My Drive/Fax/FINKI/Semestar-8/IIS/Project/real-time-sign-language-recognition-macedonian/train/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"URZ-43t09Vsa"},"source":["os.makedirs(f'{root}/train/train', exist_ok = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CZ2IgQjN9GAg"},"source":["train_folder_files = os.listdir('./train')\n","for file in train_folder_files:\n","  if file == 'train': continue\n","  shutil.copyfile('./train/' + file, f'{root}train/{file}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Wp5DZzTvnQr"},"source":["train_train_files = os.listdir('./train/train')\n","for file in train_train_files:\n","  shutil.copyfile('./train/train/' + file, f'{root}train/train/{file}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6U7EBcz0GcE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630949804883,"user_tz":-120,"elapsed":17,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"191b1949-961e-4320-fe59-f1dfe55b3f0e"},"source":["train_folder_files"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ckpt-2.data-00000-of-00001',\n"," 'ckpt-1.data-00000-of-00001',\n"," 'checkpoint',\n"," 'train',\n"," 'ckpt-1.index',\n"," 'ckpt-2.index']"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","metadata":{"id":"PDEO6ud68V_i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630949869783,"user_tz":-120,"elapsed":64906,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"3b19012b-95c1-443f-dfde-ab8f15f3baef"},"source":["!python ./research/object_detection/exporter_main_v2.py \\\n","    --trained_checkpoint_dir=./train \\\n","    --pipeline_config_path=./pipeline.config \\\n","    --output_directory=./fine_tune_model"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-09-06 17:36:47.121947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:36:47.132753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:36:47.133504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:36:47.142872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:36:47.143671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:36:47.144437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:36:47.624150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:36:47.624973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:36:47.625756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-06 17:36:47.626487: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-09-06 17:36:47.626561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10819 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","W0906 17:36:47.811596 140177153980288 deprecation.py:616] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0906 17:36:54.693610 140177153980288 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0906 17:36:54.694182 140177153980288 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0906 17:36:54.694474 140177153980288 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0906 17:36:54.694801 140177153980288 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0906 17:36:54.695172 140177153980288 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0906 17:36:54.695542 140177153980288 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f7d2040e650>, because it is not built.\n","W0906 17:37:05.401865 140177153980288 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f7d2040e650>, because it is not built.\n","2021-09-06 17:37:18.843572: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","W0906 17:37:41.096839 140177153980288 save.py:254] Found untraced functions such as BoxPredictor_layer_call_fn, BoxPredictor_layer_call_and_return_conditional_losses, BoxPredictor_layer_call_fn, BoxPredictor_layer_call_and_return_conditional_losses, BoxPredictor_layer_call_and_return_conditional_losses while saving (showing 5 of 125). These functions will not be directly callable after loading.\n","INFO:tensorflow:Assets written to: ./fine_tune_model/saved_model/assets\n","I0906 17:37:46.695040 140177153980288 builder_impl.py:781] Assets written to: ./fine_tune_model/saved_model/assets\n","INFO:tensorflow:Writing pipeline config file to ./fine_tune_model/pipeline.config\n","I0906 17:37:47.503916 140177153980288 config_util.py:254] Writing pipeline config file to ./fine_tune_model/pipeline.config\n"]}]},{"cell_type":"code","metadata":{"id":"JMefyUe7wyzM"},"source":["os.makedirs('/content/drive/My Drive/Fax/FINKI/Semestar-8/IIS/Project/real-time-sign-language-recognition-macedonian/fine_tune_model', exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HxiIzQrUwmkX"},"source":["%cp -r ./fine_tune_model '/content/drive/My Drive/Fax/FINKI/Semestar-8/IIS/Project/real-time-sign-language-recognition-macedonian/fine_tune_model/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"wyH9DgkBEecX","executionInfo":{"status":"ok","timestamp":1630949870133,"user_tz":-120,"elapsed":12,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"e3781d2c-2575-4b5a-f7cd-75d0d3b4d51b"},"source":["%pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/usr/local/lib/python3.7/dist-packages/tensorflow/models'"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"YX_nj03wG3tH"},"source":["%cp ./pipeline.config '/content/drive/My Drive/Fax/FINKI/Semestar-8/IIS/Project/real-time-sign-language-recognition-macedonian/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-oQFRaIT1bgK"},"source":["# 7. Load Train Model From Checkpoint"]},{"cell_type":"code","metadata":{"id":"-0s0OgffpPdB"},"source":["import os\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZSLaKs8oHMM"},"source":["CONFIG_PATH = f'{root}/pipeline.config'\n","CHECKPOINT_PATH = f'{root}/train/'\n","PATH_TO_SAVED_MODEL = f'{root}fine_tune_model/fine_tune_model/saved_model'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fY7oJwY-jcem","executionInfo":{"status":"ok","timestamp":1631017388818,"user_tz":-120,"elapsed":652,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"1179a471-ff9d-4ac6-9987-e74180d03c6e"},"source":["ckpt_files = os.listdir(CHECKPOINT_PATH)\n","ckpt_files"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['train',\n"," 'ckpt-2.data-00000-of-00001',\n"," 'ckpt-1.data-00000-of-00001',\n"," 'checkpoint',\n"," 'ckpt-1.index',\n"," 'ckpt-2.index']"]},"metadata":{},"execution_count":144}]},{"cell_type":"code","metadata":{"id":"v_TjduY51bgK"},"source":["# Load pipeline config and build a detection model\n","configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n","detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-2')).expect_partial()\n","\n","detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hqQo5P-P1bgK"},"source":["# 8. Detect in Real-Time"]},{"cell_type":"code","metadata":{"id":"0iAQWLtSsoPP","executionInfo":{"status":"ok","timestamp":1631109503266,"user_tz":-120,"elapsed":324,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import cv2 \n","import numpy as np\n","import time"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"tlePY-fh1bgK"},"source":["category_index = label_map_util.create_category_index_from_labelmap(f'{root}workspace/annotations/label_map.pbtxt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TYVXw5mlyeom"},"source":["## EXAMPLE 2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pW0_KBnmu5vi","executionInfo":{"status":"ok","timestamp":1631017403403,"user_tz":-120,"elapsed":46,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"514dbad7-acd6-4ef1-b6fa-6e60b3bc12fc"},"source":["#Loading the image\n","img=os.listdir('./images/test')\n","print(img)\n","imgs = []\n","for im in img:\n","  new_img = './images/test/' + im\n","  imgs.append(new_img)\n","print(imgs)\n","#list containing paths of all the images"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['b.5c16aac2-d400-11eb-84e0-5cf3709ec7ac.jpg', 'b.5d4c4a0c-d400-11eb-830e-5cf3709ec7ac.jpg', 'a.4ae799c6-d400-11eb-930d-5cf3709ec7ac.jpg', 'a.4c1c8db4-d400-11eb-80f6-5cf3709ec7ac.jpg']\n","['./images/test/b.5c16aac2-d400-11eb-84e0-5cf3709ec7ac.jpg', './images/test/b.5d4c4a0c-d400-11eb-830e-5cf3709ec7ac.jpg', './images/test/a.4ae799c6-d400-11eb-930d-5cf3709ec7ac.jpg', './images/test/a.4c1c8db4-d400-11eb-80f6-5cf3709ec7ac.jpg']\n"]}]},{"cell_type":"code","metadata":{"id":"OruLaOHU1KEz"},"source":["import io\n","import os\n","import scipy.misc\n","import numpy as np\n","import six\n","import time\n","import glob\n","from IPython.display import display\n","\n","from six import BytesIO\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageDraw, ImageFont\n","\n","import tensorflow as tf\n","from object_detection.utils import ops as utils_ops\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n","\n","%matplotlib inline\n","\n","\n","def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: a file path (this can be local or on colossus)\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OOfowlfG05wh"},"source":["def run_inference_for_single_image(image):\n","  image = np.asarray(image)\n","  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","  input_tensor = tf.convert_to_tensor(image)\n","  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","  input_tensor = input_tensor[tf.newaxis,...]\n","\n","  # Run inference\n","  model_fn = detect_fn\n","  output_dict = model_fn(input_tensor)\n","\n","  # All outputs are batches tensors.\n","  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","  # We're only interested in the first num_detections.\n","  num_detections = int(output_dict.pop('num_detections'))\n","  output_dict = {key:value[0, :num_detections].numpy() \n","                 for key,value in output_dict.items()}\n","  output_dict['num_detections'] = num_detections\n","\n","  # detection_classes should be ints.\n","  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n","   \n","  # Handle models with masks:\n","  if 'detection_masks' in output_dict:\n","    # Reframe the the bbox mask to the image size.\n","    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","              output_dict['detection_masks'], output_dict['detection_boxes'],\n","               image.shape[0], image.shape[1])      \n","    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n","                                       tf.uint8)\n","    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n","    \n","  return output_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6XY4nh409_E"},"source":["image_path = imgs[2]\n","image_np = load_image_into_numpy_array(image_path)\n","#print(image_np)\n","input_tensor = np.expand_dims(image_np, 0)\n","start_time = time.time()\n","detections = detect_fn(input_tensor)\n","end_time = time.time()\n","# elapsed.append(end_time - start_time)\n","#print(detections['detection_scores'])\n","\n","plt.rcParams['figure.figsize'] = [42, 21]\n","label_id_offset = 1\n","image_np_with_detections = image_np.copy()\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_detections,\n","      detections['detection_boxes'][0].numpy(),\n","      detections['detection_classes'][0].numpy().astype(np.int32),\n","      detections['detection_scores'][0].numpy(),\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=3,\n","      min_score_thresh=.50,\n","      agnostic_mode=False)\n","plt.subplot(2, 1, 0+1)\n","plt.imshow(image_np_with_detections)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4AcZrAZrPxXj"},"source":["def make_predictions(image_path):\n","  image_np = load_image_into_numpy_array(image_path)\n","  #print(image_np)\n","  input_tensor = np.expand_dims(image_np, 0)\n","  start_time = time.time()\n","  detections = detect_fn(input_tensor)\n","  end_time = time.time()\n","  # elapsed.append(end_time - start_time)\n","  #print(detections['detection_scores'])\n","\n","  plt.rcParams['figure.figsize'] = [42, 21]\n","  label_id_offset = 1\n","  image_np_with_detections = image_np.copy()\n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","        image_np_with_detections,\n","        detections['detection_boxes'][0].numpy(),\n","        detections['detection_classes'][0].numpy().astype(np.int32),\n","        detections['detection_scores'][0].numpy(),\n","        category_index,\n","        use_normalized_coordinates=True,\n","        max_boxes_to_draw=3,\n","        min_score_thresh=.50,\n","        agnostic_mode=False)\n","  plt.subplot(2, 1, 0+1)\n","  plt.imshow(image_np_with_detections)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aHgIhLRAyv9H"},"source":["## EXAMPLE 1"]},{"cell_type":"code","metadata":{"id":"PvD2mfh61bgL"},"source":["|# Setup capture\n","cap = cv2.VideoCapture(0)\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RN3P_U-qw6_X"},"source":["cap = cv2.VideoCapture(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7TUVakbc1bgL","colab":{"base_uri":"https://localhost:8080/","height":516},"executionInfo":{"status":"error","timestamp":1631010409684,"user_tz":-120,"elapsed":516,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"2bf5e416-d5a4-4ec8-ddda-2bfc11a13861"},"source":["while True: \n","    ret, frame = cap.read()\n","    print(frame)\n","    image_np = np.array(frame)\n","    print(image_np)\n","    # image_np = load_image_into_numpy_array(img)\n","\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","\n","    detections = detect_fn(input_tensor) \n","    output_dict = detections\n","\n","\n","    plt.rcParams['figure.figsize'] = [42, 21]\n","    label_id_offset = 1\n","    image_np_with_detections = image_np.copy()\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","          image_np_with_detections,\n","          detections['detection_boxes'][0].numpy(),\n","          detections['detection_classes'][0].numpy().astype(np.int32),\n","          detections['detection_scores'][0].numpy(),\n","          category_index,\n","          use_normalized_coordinates=True,\n","          max_boxes_to_draw=3,\n","          min_score_thresh=.50,\n","          agnostic_mode=False)\n","\n","    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n","    \n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        cap.release()\n","        break"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n","None\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_convert_inputs_to_signature\u001b[0;34m(inputs, input_signature, flat_input_signature)\u001b[0m\n\u001b[1;32m   2879\u001b[0m         flatten_inputs[index] = ops.convert_to_tensor(\n\u001b[0;32m-> 2880\u001b[0;31m             value, dtype_hint=spec.dtype)\n\u001b[0m\u001b[1;32m   2881\u001b[0m         \u001b[0mneed_packing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType).","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-177-3dbefe5bc18e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimage_np_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m-> 3038\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3415\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_function_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3417\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3418\u001b[0m       \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcanonicalize_function_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m       \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m       inputs, flat_inputs, filtered_flat_inputs = _convert_inputs_to_signature(\n\u001b[0;32m-> 2787\u001b[0;31m           inputs, self._input_signature, self._flat_input_signature)\n\u001b[0m\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_convert_inputs_to_signature\u001b[0;34m(inputs, input_signature, flat_input_signature)\u001b[0m\n\u001b[1;32m   2884\u001b[0m                          \u001b[0;34m\"the Python function must be convertible to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2885\u001b[0m                          \u001b[0;34m\"tensors:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2886\u001b[0;31m                          format_error_message(inputs, input_signature))\n\u001b[0m\u001b[1;32m   2887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2888\u001b[0m   if any(not spec.is_compatible_with(other) for spec, other in zip(\n","\u001b[0;31mValueError\u001b[0m: When input_signature is provided, all inputs to the Python function must be convertible to tensors:\n  inputs: (\n    [None])\n  input_signature: (\n    TensorSpec(shape=(1, None, None, 3), dtype=tf.uint8, name='input_tensor'))"]}]},{"cell_type":"code","metadata":{"id":"cMKCzcxa1bgL"},"source":["detections = detect_fn(input_tensor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EuJ5lbXd1bgL"},"source":["from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"laL5hOWo1bgM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fj9YcAnsT4B_"},"source":["# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWQrfX5L3YTg"},"source":["## Helper Functions\n","Below are a few helper function to make converting between different image data types and formats. "]},{"cell_type":"code","metadata":{"id":"YgdSqgMb4e8f"},"source":["# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","from PIL import Image as ImagePIL\n","import io\n","import html\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjQgNWwe3YTg"},"source":["# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","\n","  image = ImagePIL.open(BytesIO(image_bytes))\n","  (im_width, im_height) = image.size\n","  image_np = np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img, image_np\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-O2nOrV_3YTg"},"source":["## Haar Cascade Classifier\n","For this tutorial we will run a simple object detection algorithm called Haar Cascade on our images and video fetched from our webcam. OpenCV has a pre-trained Haar Cascade face detection model. "]},{"cell_type":"code","metadata":{"id":"gEPkoOIa3YTg"},"source":["# initialize the Haar Cascade face detection model\n","face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aLssfkQB3YTi"},"source":["## Webcam Videos\n","Running code on webcam video is a little more complex than images. We need to start a video stream using our webcam as input. Then we run each frame through our progam (face detection) and create an overlay image that contains bounding box of detection(s). We then overlay the bounding box image back onto the next frame of our video stream.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"NnyJpt7j3YTi"},"source":["# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","  \n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h57zBGRY3YTj"},"source":["# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","# initialze bounding box to empty\n","bbox = ''\n","count = 0 \n","while True:\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","\n","    # convert JS response to OpenCV Image\n","    img, image_np = js_to_image(js_reply[\"img\"])\n","\n","    \n","    input_tensor = np.expand_dims(image_np, 0)\n","    start_time = time.time()\n","    detections = detect_fn(input_tensor)\n","    output_dict = detections\n","    end_time = time.time()\n","    # elapsed.append(end_time - start_time)\n","    # print(detections['detection_scores'])\n","\n","    plt.rcParams['figure.figsize'] = [42, 21]\n","    label_id_offset = 1\n","    image_np_with_detections = image_np.copy()\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","          image_np_with_detections,\n","          detections['detection_boxes'][0].numpy(),\n","          detections['detection_classes'][0].numpy().astype(np.int32),\n","          detections['detection_scores'][0].numpy(),\n","          category_index,\n","          use_normalized_coordinates=True,\n","          max_boxes_to_draw=3,\n","          min_score_thresh=.50,\n","          agnostic_mode=False)\n","    # print(jpg_as_np)\n","\n","    boxes = np.squeeze(detections['detection_boxes'][0].numpy())\n","    scores = np.squeeze(detections['detection_scores'][0].numpy().astype(np.int32))\n","    print(scores)\n","    #set a min thresh score, say 0.8\n","    min_score_thresh = 0.1\n","    bboxes = boxes[scores > min_score_thresh]\n","\n","    #get image size\n","    im_width, im_height = 480,640\n","    final_box = []\n","    for box in bboxes:\n","        ymin, xmin, ymax, xmax = box\n","        final_box.append([xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height])\n","\n","    # print(final_box)\n","\n","    # create transparent overlay for bounding box\n","    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n","\n","    # grayscale image for face detection\n","    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","\n","    # get face region coordinates\n","    faces = face_cascade.detectMultiScale(gray)\n","    # get face bounding box for overlay\n","    for (x,y,w,h) in faces:\n","      bbox_array = cv2.rectangle(bbox_array,(x,y),(x+w,y+h),(255,0,0),2)\n","\n","    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n","    # convert overlay of bbox into bytes\n","    bbox_bytes = bbox_to_bytes(bbox_array)\n","    # update bbox so next frame gets new overlay\n","    bbox = bbox_bytes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XDD8EdN-3YTj"},"source":["## Hope You Enjoyed!\n","If you enjoyed the tutorial and want to see more videos or tutorials check out my YouTube channel [HERE](https://www.youtube.com/channel/UCrydcKaojc44XnuXrfhlV8Q?sub_confirmation=1)\n","\n","Have a great day!"]},{"cell_type":"code","metadata":{"id":"ocNxYqZoPlFN"},"source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","  data = eval_js('takePhoto({})'.format(quality))\n","  binary = b64decode(data.split(',')[1])\n","  with open(filename, 'wb') as f:\n","    f.write(binary)\n","  return filename"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5tLYBXw4Pk6H"},"source":["#from IPython.display import Image\n","try:\n","  filename = take_photo()\n","  print('Saved to {}'.format(filename))\n","  \n","  # Show the image which was just taken.\n","  make_predictions(filename)\n","except Exception as err:\n","  # Errors will be thrown if the user does not have a webcam or if they do not\n","  # grant the page permission to access it.\n","  print(str(err))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wprNWy3MQp50"},"source":[""],"execution_count":null,"outputs":[]}]}