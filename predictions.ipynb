{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"predictions.ipynb","provenance":[],"authorship_tag":"ABX9TyMJ9AmxTkQ0/KL2Pbe0SUHc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"HvrbH_j-zG-Z"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KCAd1qYNtgB4","executionInfo":{"status":"ok","timestamp":1631111126700,"user_tz":-120,"elapsed":7,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["import os\n","import shutil"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qdD0tr0U1vIt","executionInfo":{"status":"ok","timestamp":1631111129679,"user_tz":-120,"elapsed":2984,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"9a218572-e218-498c-a3bc-044371b63bb7"},"source":["import tensorflow\n","print(tensorflow.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["2.6.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awaDCB821tnI","executionInfo":{"status":"ok","timestamp":1631111276100,"user_tz":-120,"elapsed":146429,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"a52d30ba-74b5-4143-c6f5-47328d92a3d0"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"H62an9qW1xri"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpPVXAdo16VW","executionInfo":{"status":"ok","timestamp":1631111276102,"user_tz":-120,"elapsed":23,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"27381be6-7679-466d-bc74-dc584f1d7cd9"},"source":["%cd .."],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y3jnd030sfmO","executionInfo":{"status":"ok","timestamp":1631111276103,"user_tz":-120,"elapsed":16,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"47ffe4f5-08b2-48cb-d553-31b623af6fab"},"source":["%cd /usr/local/lib/python3.7/dist-packages/tensorflow"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tensorflow\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FOLD59wgslen","executionInfo":{"status":"ok","timestamp":1631111298877,"user_tz":-120,"elapsed":22786,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"800d4059-4ea5-4c0c-8627-06c5fa52f0e7"},"source":["!git clone https://github.com/tensorflow/models.git"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 61617, done.\u001b[K\n","remote: Counting objects: 100% (1/1), done.\u001b[K\n","remote: Total 61617 (delta 0), reused 0 (delta 0), pack-reused 61616\u001b[K\n","Receiving objects: 100% (61617/61617), 574.27 MiB | 31.21 MiB/s, done.\n","Resolving deltas: 100% (42893/42893), done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pN4QOZ87tGqh","executionInfo":{"status":"ok","timestamp":1631111298878,"user_tz":-120,"elapsed":22,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"8d7f0eba-1095-4735-c860-339def074ec3"},"source":["%cd models/research/"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/models/research\n"]}]},{"cell_type":"code","metadata":{"id":"qljg1iZK01ni","executionInfo":{"status":"ok","timestamp":1631111298879,"user_tz":-120,"elapsed":13,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["os.environ['PYTHONPATH'] += f':/usr/local/lib/python3.7/dist-packages/tensorflow/models/'\n","os.environ['PYTHONPATH'] += f':/usr/local/lib/python3.7/dist-packages/tensorflow/models/research/'\n","os.environ['PYTHONPATH'] += f':/usr/local/lib/python3.7/dist-packages/tensorflow/models/research/slim/'\n","os.environ['PYTHONPATH'] += f':/usr/local/lib/python3.7/dist-packages/tensorflow/models/research/object_detection/'"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uCDGLpvX0bob","executionInfo":{"status":"ok","timestamp":1631111303643,"user_tz":-120,"elapsed":4775,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"80d37f9e-30ee-4c85-bbf5-7c953ae44993"},"source":["!pip install tf_slim"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tf_slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 3.1 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VD6IoPaMtNId","executionInfo":{"status":"ok","timestamp":1631111303644,"user_tz":-120,"elapsed":33,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"1918dfe9-6173-4728-e2a2-b70cee6e935f"},"source":["! echo $PYTHONPATH"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/env/python:/usr/local/lib/python3.7/dist-packages/tensorflow/models/:/usr/local/lib/python3.7/dist-packages/tensorflow/models/research/:/usr/local/lib/python3.7/dist-packages/tensorflow/models/research/slim/:/usr/local/lib/python3.7/dist-packages/tensorflow/models/research/object_detection/\n"]}]},{"cell_type":"code","metadata":{"id":"2_lWTz9ytKV6","executionInfo":{"status":"ok","timestamp":1631111304001,"user_tz":-120,"elapsed":379,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["!protoc object_detection/protos/*.proto --python_out=."],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"VGRJ6gkeuEtV","executionInfo":{"status":"ok","timestamp":1631111304002,"user_tz":-120,"elapsed":6,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["!cp object_detection/packages/tf2/setup.py ."],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Zhvq_IJU0Rb","executionInfo":{"status":"ok","timestamp":1631111342944,"user_tz":-120,"elapsed":38947,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"c1dc6252-61af-4c3f-b0fd-390dc8fa4785"},"source":["!python -m pip install ."],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /usr/local/lib/python3.7/dist-packages/tensorflow/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.32.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n","\u001b[K     |████████████████████████████████| 9.8 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 68.9 MB/s \n","\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 63.6 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 8.4 MB/s \n","\u001b[?25hCollecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 7.8 MB/s \n","\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n","\u001b[K     |████████████████████████████████| 37.1 MB 44 kB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.2 MB/s \n","\u001b[?25hCollecting tensorflow-text>=2.5.0\n","  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 38.2 MB/s \n","\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n","\u001b[K     |████████████████████████████████| 211 kB 68.6 MB/s \n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 50.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 52.9 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.34.0)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n","Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.39.0)\n","Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (5.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.5)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (4.6.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 621 kB/s \n","\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.0)\n","Collecting fastavro<2,>=0.21.4\n","  Downloading fastavro-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 46.0 MB/s \n","\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 25.6 MB/s \n","\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting future<1.0.0,>=0.18.2\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 61.5 MB/s \n","\u001b[?25hCollecting orjson<4.0\n","  Downloading orjson-3.6.3-cp37-cp37m-manylinux_2_24_x86_64.whl (234 kB)\n","\u001b[K     |████████████████████████████████| 234 kB 74.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting avro-python3\n","  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.5.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.2.2)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n","Building wheels for collected packages: object-detection, py-cpuinfo, avro-python3, dill, future, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1665159 sha256=d3b401e0cdd764e0ef932967cfb9b5ef667225fd97534dc5dce3c018eab23087\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-04gucdgm/wheels/c0/29/42/e79b21f860d3b99c7c1f49f1333297a2d951ae8275188f125d\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22258 sha256=201fecda50b9c95c89c2c6a73843e787b2f6c9422fbb03d68829a88eb543d39f\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=4180722dd985b91ef021d6e09c36e3c74b4e543aea491759a7288e1de220d30a\n","  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=3aaf0798df00910f18435cb7d04f89311b9bd6a5a0f08db2dcbc254027772eb1\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=0a4513525e0be6ca52cba3d96692b2b87c6088f7ba12c10f530a480818cffdee\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=2ae6f17197351ec67719a47c051091bf63b44233c8157fee429e8c36c419318e\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo avro-python3 dill future seqeval\n","Installing collected packages: requests, portalocker, future, dill, colorama, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, orjson, opencv-python-headless, hdfs, fastavro, avro-python3, tf-models-official, lvis, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed apache-beam-2.32.0 avro-python3-1.9.2.1 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.4 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.3.56 orjson-3.6.3 portalocker-2.3.2 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.26.0 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.14.0 tensorflow-model-optimization-0.6.0 tensorflow-text-2.6.0 tf-models-official-2.6.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdBjpg4XWmy2","executionInfo":{"status":"ok","timestamp":1631111386552,"user_tz":-120,"elapsed":43619,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"b1f4d484-7a46-4b56-b5e0-ae6cd3c812b7"},"source":["!python object_detection/builders/model_builder_tf2_test.py"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-09-08 14:29:07.134658: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2021-09-08 14:29:07.134718: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (9e08221f2f8b): /proc/driver/nvidia/version does not exist\n","Running tests under Python 3.7.11: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","W0908 14:29:07.571652 140192368248704 model_builder.py:1091] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.87s\n","I0908 14:29:08.017018 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.87s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.58s\n","I0908 14:29:08.596015 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.58s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.33s\n","I0908 14:29:08.925983 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.33s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.31s\n","I0908 14:29:09.239048 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.31s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","W0908 14:29:09.242649 140192368248704 mobilenet_v2.py:297] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9412608/9406464 [==============================] - 0s 0us/step\n","9420800/9406464 [==============================] - 0s 0us/step\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.74s\n","I0908 14:29:11.983134 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.74s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0908 14:29:11.984803 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","I0908 14:29:12.016743 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I0908 14:29:12.035328 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I0908 14:29:12.058577 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n","I0908 14:29:12.187682 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n","I0908 14:29:12.311681 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n","I0908 14:29:12.445170 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n","I0908 14:29:12.586763 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n","I0908 14:29:12.716584 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n","I0908 14:29:12.753545 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0908 14:29:13.129676 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0908 14:29:13.129887 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n","I0908 14:29:13.129976 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n","I0908 14:29:13.132829 140192368248704 efficientnet_model.py:147] round_filter input=32 output=32\n","I0908 14:29:13.155879 140192368248704 efficientnet_model.py:147] round_filter input=32 output=32\n","I0908 14:29:13.156088 140192368248704 efficientnet_model.py:147] round_filter input=16 output=16\n","I0908 14:29:13.227832 140192368248704 efficientnet_model.py:147] round_filter input=16 output=16\n","I0908 14:29:13.228047 140192368248704 efficientnet_model.py:147] round_filter input=24 output=24\n","I0908 14:29:13.413436 140192368248704 efficientnet_model.py:147] round_filter input=24 output=24\n","I0908 14:29:13.413659 140192368248704 efficientnet_model.py:147] round_filter input=40 output=40\n","I0908 14:29:13.587014 140192368248704 efficientnet_model.py:147] round_filter input=40 output=40\n","I0908 14:29:13.587223 140192368248704 efficientnet_model.py:147] round_filter input=80 output=80\n","I0908 14:29:13.872041 140192368248704 efficientnet_model.py:147] round_filter input=80 output=80\n","I0908 14:29:13.872242 140192368248704 efficientnet_model.py:147] round_filter input=112 output=112\n","I0908 14:29:14.157031 140192368248704 efficientnet_model.py:147] round_filter input=112 output=112\n","I0908 14:29:14.157262 140192368248704 efficientnet_model.py:147] round_filter input=192 output=192\n","I0908 14:29:14.587404 140192368248704 efficientnet_model.py:147] round_filter input=192 output=192\n","I0908 14:29:14.587638 140192368248704 efficientnet_model.py:147] round_filter input=320 output=320\n","I0908 14:29:14.701018 140192368248704 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0908 14:29:14.763347 140192368248704 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:29:14.835229 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0908 14:29:14.835441 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n","I0908 14:29:14.835535 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n","I0908 14:29:14.837800 140192368248704 efficientnet_model.py:147] round_filter input=32 output=32\n","I0908 14:29:14.855859 140192368248704 efficientnet_model.py:147] round_filter input=32 output=32\n","I0908 14:29:14.856061 140192368248704 efficientnet_model.py:147] round_filter input=16 output=16\n","I0908 14:29:14.998181 140192368248704 efficientnet_model.py:147] round_filter input=16 output=16\n","I0908 14:29:14.998386 140192368248704 efficientnet_model.py:147] round_filter input=24 output=24\n","I0908 14:29:15.278287 140192368248704 efficientnet_model.py:147] round_filter input=24 output=24\n","I0908 14:29:15.278502 140192368248704 efficientnet_model.py:147] round_filter input=40 output=40\n","I0908 14:29:15.570507 140192368248704 efficientnet_model.py:147] round_filter input=40 output=40\n","I0908 14:29:15.570755 140192368248704 efficientnet_model.py:147] round_filter input=80 output=80\n","I0908 14:29:15.963315 140192368248704 efficientnet_model.py:147] round_filter input=80 output=80\n","I0908 14:29:15.963535 140192368248704 efficientnet_model.py:147] round_filter input=112 output=112\n","I0908 14:29:16.358089 140192368248704 efficientnet_model.py:147] round_filter input=112 output=112\n","I0908 14:29:16.358298 140192368248704 efficientnet_model.py:147] round_filter input=192 output=192\n","I0908 14:29:16.899438 140192368248704 efficientnet_model.py:147] round_filter input=192 output=192\n","I0908 14:29:16.899669 140192368248704 efficientnet_model.py:147] round_filter input=320 output=320\n","I0908 14:29:17.154516 140192368248704 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0908 14:29:17.220409 140192368248704 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:29:17.449919 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0908 14:29:17.450127 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n","I0908 14:29:17.450189 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n","I0908 14:29:17.452254 140192368248704 efficientnet_model.py:147] round_filter input=32 output=32\n","I0908 14:29:17.471966 140192368248704 efficientnet_model.py:147] round_filter input=32 output=32\n","I0908 14:29:17.472172 140192368248704 efficientnet_model.py:147] round_filter input=16 output=16\n","I0908 14:29:17.614053 140192368248704 efficientnet_model.py:147] round_filter input=16 output=16\n","I0908 14:29:17.614245 140192368248704 efficientnet_model.py:147] round_filter input=24 output=24\n","I0908 14:29:17.888742 140192368248704 efficientnet_model.py:147] round_filter input=24 output=24\n","I0908 14:29:17.888943 140192368248704 efficientnet_model.py:147] round_filter input=40 output=48\n","I0908 14:29:18.164064 140192368248704 efficientnet_model.py:147] round_filter input=40 output=48\n","I0908 14:29:18.164286 140192368248704 efficientnet_model.py:147] round_filter input=80 output=88\n","I0908 14:29:18.539644 140192368248704 efficientnet_model.py:147] round_filter input=80 output=88\n","I0908 14:29:18.539845 140192368248704 efficientnet_model.py:147] round_filter input=112 output=120\n","I0908 14:29:18.934978 140192368248704 efficientnet_model.py:147] round_filter input=112 output=120\n","I0908 14:29:18.935203 140192368248704 efficientnet_model.py:147] round_filter input=192 output=208\n","I0908 14:29:19.485606 140192368248704 efficientnet_model.py:147] round_filter input=192 output=208\n","I0908 14:29:19.485804 140192368248704 efficientnet_model.py:147] round_filter input=320 output=352\n","I0908 14:29:19.753724 140192368248704 efficientnet_model.py:147] round_filter input=1280 output=1408\n","I0908 14:29:19.821329 140192368248704 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:29:19.904581 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0908 14:29:19.904814 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n","I0908 14:29:19.904908 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n","I0908 14:29:19.906927 140192368248704 efficientnet_model.py:147] round_filter input=32 output=40\n","I0908 14:29:19.926889 140192368248704 efficientnet_model.py:147] round_filter input=32 output=40\n","I0908 14:29:19.927104 140192368248704 efficientnet_model.py:147] round_filter input=16 output=24\n","I0908 14:29:20.082255 140192368248704 efficientnet_model.py:147] round_filter input=16 output=24\n","I0908 14:29:20.082466 140192368248704 efficientnet_model.py:147] round_filter input=24 output=32\n","I0908 14:29:20.368128 140192368248704 efficientnet_model.py:147] round_filter input=24 output=32\n","I0908 14:29:20.368325 140192368248704 efficientnet_model.py:147] round_filter input=40 output=48\n","I0908 14:29:20.647087 140192368248704 efficientnet_model.py:147] round_filter input=40 output=48\n","I0908 14:29:20.647360 140192368248704 efficientnet_model.py:147] round_filter input=80 output=96\n","I0908 14:29:21.176731 140192368248704 efficientnet_model.py:147] round_filter input=80 output=96\n","I0908 14:29:21.176953 140192368248704 efficientnet_model.py:147] round_filter input=112 output=136\n","I0908 14:29:21.693053 140192368248704 efficientnet_model.py:147] round_filter input=112 output=136\n","I0908 14:29:21.693265 140192368248704 efficientnet_model.py:147] round_filter input=192 output=232\n","I0908 14:29:22.422472 140192368248704 efficientnet_model.py:147] round_filter input=192 output=232\n","I0908 14:29:22.422764 140192368248704 efficientnet_model.py:147] round_filter input=320 output=384\n","I0908 14:29:22.711288 140192368248704 efficientnet_model.py:147] round_filter input=1280 output=1536\n","I0908 14:29:22.779026 140192368248704 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:29:23.123555 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0908 14:29:23.123804 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n","I0908 14:29:23.123915 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0908 14:29:23.126055 140192368248704 efficientnet_model.py:147] round_filter input=32 output=48\n","I0908 14:29:23.145240 140192368248704 efficientnet_model.py:147] round_filter input=32 output=48\n","I0908 14:29:23.145437 140192368248704 efficientnet_model.py:147] round_filter input=16 output=24\n","I0908 14:29:23.291158 140192368248704 efficientnet_model.py:147] round_filter input=16 output=24\n","I0908 14:29:23.291374 140192368248704 efficientnet_model.py:147] round_filter input=24 output=32\n","I0908 14:29:23.661342 140192368248704 efficientnet_model.py:147] round_filter input=24 output=32\n","I0908 14:29:23.661573 140192368248704 efficientnet_model.py:147] round_filter input=40 output=56\n","I0908 14:29:24.049570 140192368248704 efficientnet_model.py:147] round_filter input=40 output=56\n","I0908 14:29:24.049822 140192368248704 efficientnet_model.py:147] round_filter input=80 output=112\n","I0908 14:29:24.649194 140192368248704 efficientnet_model.py:147] round_filter input=80 output=112\n","I0908 14:29:24.649387 140192368248704 efficientnet_model.py:147] round_filter input=112 output=160\n","I0908 14:29:25.294579 140192368248704 efficientnet_model.py:147] round_filter input=112 output=160\n","I0908 14:29:25.294816 140192368248704 efficientnet_model.py:147] round_filter input=192 output=272\n","I0908 14:29:26.317231 140192368248704 efficientnet_model.py:147] round_filter input=192 output=272\n","I0908 14:29:26.317440 140192368248704 efficientnet_model.py:147] round_filter input=320 output=448\n","I0908 14:29:26.613676 140192368248704 efficientnet_model.py:147] round_filter input=1280 output=1792\n","I0908 14:29:26.691602 140192368248704 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:29:26.783298 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0908 14:29:26.783511 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n","I0908 14:29:26.783622 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0908 14:29:26.785584 140192368248704 efficientnet_model.py:147] round_filter input=32 output=48\n","I0908 14:29:26.803215 140192368248704 efficientnet_model.py:147] round_filter input=32 output=48\n","I0908 14:29:26.803423 140192368248704 efficientnet_model.py:147] round_filter input=16 output=24\n","I0908 14:29:27.051247 140192368248704 efficientnet_model.py:147] round_filter input=16 output=24\n","I0908 14:29:27.051456 140192368248704 efficientnet_model.py:147] round_filter input=24 output=40\n","I0908 14:29:27.517274 140192368248704 efficientnet_model.py:147] round_filter input=24 output=40\n","I0908 14:29:27.517483 140192368248704 efficientnet_model.py:147] round_filter input=40 output=64\n","I0908 14:29:27.997878 140192368248704 efficientnet_model.py:147] round_filter input=40 output=64\n","I0908 14:29:27.998086 140192368248704 efficientnet_model.py:147] round_filter input=80 output=128\n","I0908 14:29:28.714610 140192368248704 efficientnet_model.py:147] round_filter input=80 output=128\n","I0908 14:29:28.714814 140192368248704 efficientnet_model.py:147] round_filter input=112 output=176\n","I0908 14:29:29.750968 140192368248704 efficientnet_model.py:147] round_filter input=112 output=176\n","I0908 14:29:29.751164 140192368248704 efficientnet_model.py:147] round_filter input=192 output=304\n","I0908 14:29:30.974441 140192368248704 efficientnet_model.py:147] round_filter input=192 output=304\n","I0908 14:29:30.974701 140192368248704 efficientnet_model.py:147] round_filter input=320 output=512\n","I0908 14:29:31.553503 140192368248704 efficientnet_model.py:147] round_filter input=1280 output=2048\n","I0908 14:29:31.639497 140192368248704 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:29:31.753965 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0908 14:29:31.754179 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0908 14:29:31.754265 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0908 14:29:31.756375 140192368248704 efficientnet_model.py:147] round_filter input=32 output=56\n","I0908 14:29:31.775372 140192368248704 efficientnet_model.py:147] round_filter input=32 output=56\n","I0908 14:29:31.775570 140192368248704 efficientnet_model.py:147] round_filter input=16 output=32\n","I0908 14:29:32.015616 140192368248704 efficientnet_model.py:147] round_filter input=16 output=32\n","I0908 14:29:32.015839 140192368248704 efficientnet_model.py:147] round_filter input=24 output=40\n","I0908 14:29:32.632929 140192368248704 efficientnet_model.py:147] round_filter input=24 output=40\n","I0908 14:29:32.633134 140192368248704 efficientnet_model.py:147] round_filter input=40 output=72\n","I0908 14:29:33.222545 140192368248704 efficientnet_model.py:147] round_filter input=40 output=72\n","I0908 14:29:33.222756 140192368248704 efficientnet_model.py:147] round_filter input=80 output=144\n","I0908 14:29:34.019468 140192368248704 efficientnet_model.py:147] round_filter input=80 output=144\n","I0908 14:29:34.019688 140192368248704 efficientnet_model.py:147] round_filter input=112 output=200\n","I0908 14:29:34.884999 140192368248704 efficientnet_model.py:147] round_filter input=112 output=200\n","I0908 14:29:34.885215 140192368248704 efficientnet_model.py:147] round_filter input=192 output=344\n","I0908 14:29:36.690204 140192368248704 efficientnet_model.py:147] round_filter input=192 output=344\n","I0908 14:29:36.690418 140192368248704 efficientnet_model.py:147] round_filter input=320 output=576\n","I0908 14:29:37.311511 140192368248704 efficientnet_model.py:147] round_filter input=1280 output=2304\n","I0908 14:29:37.407459 140192368248704 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0908 14:29:37.531573 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0908 14:29:37.531814 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0908 14:29:37.531900 140192368248704 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0908 14:29:37.534041 140192368248704 efficientnet_model.py:147] round_filter input=32 output=64\n","I0908 14:29:37.551498 140192368248704 efficientnet_model.py:147] round_filter input=32 output=64\n","I0908 14:29:37.551713 140192368248704 efficientnet_model.py:147] round_filter input=16 output=32\n","I0908 14:29:37.841087 140192368248704 efficientnet_model.py:147] round_filter input=16 output=32\n","I0908 14:29:37.841315 140192368248704 efficientnet_model.py:147] round_filter input=24 output=48\n","I0908 14:29:38.491257 140192368248704 efficientnet_model.py:147] round_filter input=24 output=48\n","I0908 14:29:38.491484 140192368248704 efficientnet_model.py:147] round_filter input=40 output=80\n","I0908 14:29:39.169092 140192368248704 efficientnet_model.py:147] round_filter input=40 output=80\n","I0908 14:29:39.169371 140192368248704 efficientnet_model.py:147] round_filter input=80 output=160\n","I0908 14:29:40.292194 140192368248704 efficientnet_model.py:147] round_filter input=80 output=160\n","I0908 14:29:40.292424 140192368248704 efficientnet_model.py:147] round_filter input=112 output=224\n","I0908 14:29:41.556508 140192368248704 efficientnet_model.py:147] round_filter input=112 output=224\n","I0908 14:29:41.556748 140192368248704 efficientnet_model.py:147] round_filter input=192 output=384\n","I0908 14:29:43.631012 140192368248704 efficientnet_model.py:147] round_filter input=192 output=384\n","I0908 14:29:43.631256 140192368248704 efficientnet_model.py:147] round_filter input=320 output=640\n","I0908 14:29:44.865933 140192368248704 efficientnet_model.py:147] round_filter input=1280 output=2560\n","I0908 14:29:44.966867 140192368248704 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 32.36s\n","I0908 14:29:45.115458 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 32.36s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0908 14:29:45.124188 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0908 14:29:45.126407 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0908 14:29:45.127128 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0908 14:29:45.129029 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0908 14:29:45.130751 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0908 14:29:45.131319 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0908 14:29:45.132492 140192368248704 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 37.989s\n","\n","OK (skipped=1)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9m0UJnHU-hm_","executionInfo":{"status":"ok","timestamp":1631111386553,"user_tz":-120,"elapsed":40,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"405e9617-a176-4a54-92cd-66d3b72dd212"},"source":["%cd .."],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/models\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gs2JfFtPtQwZ","executionInfo":{"status":"ok","timestamp":1631111389672,"user_tz":-120,"elapsed":3137,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"5e8e4265-81de-4374-d185-e3df73cf33ae"},"source":["!pip install lvis"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (0.5.3)\n","Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.2)\n","Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.24)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.1)\n","Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.4.7)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ma2PgeM5teWp","executionInfo":{"status":"ok","timestamp":1631111392853,"user_tz":-120,"elapsed":3190,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"040e4521-eb09-42ec-fd1f-51cb2478b711"},"source":["!pip install tensorflow-addons"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.14.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"]}]},{"cell_type":"code","metadata":{"id":"2FQpWWgGzWsy","executionInfo":{"status":"ok","timestamp":1631111392854,"user_tz":-120,"elapsed":31,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["root = '/content/drive/My Drive/Fax/FINKI/Semestar-8/IIS/Project/real-time-sign-language-recognition-macedonian/'"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-oQFRaIT1bgK"},"source":["# 7. Load Train Model From Checkpoint"]},{"cell_type":"code","metadata":{"id":"-0s0OgffpPdB","executionInfo":{"status":"ok","timestamp":1631111479942,"user_tz":-120,"elapsed":272,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["import os\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","from object_detection.utils import config_util\n","from object_detection.protos import pipeline_pb2\n","from google.protobuf import text_format\n","import tensorflow as tf"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZSLaKs8oHMM","executionInfo":{"status":"ok","timestamp":1631111468767,"user_tz":-120,"elapsed":3,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["CONFIG_PATH = f'{root}/pipeline.config'\n","CHECKPOINT_PATH = f'{root}/train/'\n","PATH_TO_SAVED_MODEL = f'{root}fine_tune_model/fine_tune_model/saved_model'"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fY7oJwY-jcem","executionInfo":{"status":"ok","timestamp":1631111469937,"user_tz":-120,"elapsed":14,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"ab3bcfaa-6ead-49db-ad0a-f2fc9a506c39"},"source":["ckpt_files = os.listdir(CHECKPOINT_PATH)\n","ckpt_files"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['train',\n"," 'ckpt-2.data-00000-of-00001',\n"," 'ckpt-1.data-00000-of-00001',\n"," 'checkpoint',\n"," 'ckpt-1.index',\n"," 'ckpt-2.index']"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"v_TjduY51bgK","executionInfo":{"status":"ok","timestamp":1631111502141,"user_tz":-120,"elapsed":20165,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["# Load pipeline config and build a detection model\n","configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n","detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-2')).expect_partial()\n","\n","detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hqQo5P-P1bgK"},"source":["# 8. Detect in Real-Time"]},{"cell_type":"code","metadata":{"id":"0iAQWLtSsoPP","executionInfo":{"status":"ok","timestamp":1631111506248,"user_tz":-120,"elapsed":247,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import cv2 \n","import numpy as np\n","import time"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"tlePY-fh1bgK","executionInfo":{"status":"ok","timestamp":1631111511303,"user_tz":-120,"elapsed":3817,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["category_index = label_map_util.create_category_index_from_labelmap(f'{root}workspace/annotations/label_map.pbtxt')"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TYVXw5mlyeom"},"source":["## EXAMPLE 2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pW0_KBnmu5vi","executionInfo":{"status":"ok","timestamp":1631111603670,"user_tz":-120,"elapsed":277,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}},"outputId":"362f60f4-c083-4c96-9a8d-ba7a7c9f9e89"},"source":["#Loading the image\n","img=os.listdir(f'{root}workspace/images/test')\n","print(img)\n","imgs = []\n","for im in img:\n","  if im.endswith('.xml'): continue\n","  new_img = f'{root}workspace/images/test/' + im\n","  imgs.append(new_img)\n","print(imgs)\n","#list containing paths of all the images"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["['a.4c1c8db4-d400-11eb-80f6-5cf3709ec7ac.jpg', 'b.5d4c4a0c-d400-11eb-830e-5cf3709ec7ac.jpg', 'a.4c1c8db4-d400-11eb-80f6-5cf3709ec7ac.xml', 'a.4ae799c6-d400-11eb-930d-5cf3709ec7ac.jpg', 'b.5c16aac2-d400-11eb-84e0-5cf3709ec7ac.xml', 'b.5c16aac2-d400-11eb-84e0-5cf3709ec7ac.jpg', 'a.4ae799c6-d400-11eb-930d-5cf3709ec7ac.xml', 'b.5d4c4a0c-d400-11eb-830e-5cf3709ec7ac.xml']\n","['/content/drive/My Drive/Fax/FINKI/Semestar-8/IIS/Project/real-time-sign-language-recognition-macedonian/workspace/images/test/a.4c1c8db4-d400-11eb-80f6-5cf3709ec7ac.jpg', '/content/drive/My Drive/Fax/FINKI/Semestar-8/IIS/Project/real-time-sign-language-recognition-macedonian/workspace/images/test/b.5d4c4a0c-d400-11eb-830e-5cf3709ec7ac.jpg', '/content/drive/My Drive/Fax/FINKI/Semestar-8/IIS/Project/real-time-sign-language-recognition-macedonian/workspace/images/test/a.4ae799c6-d400-11eb-930d-5cf3709ec7ac.jpg', '/content/drive/My Drive/Fax/FINKI/Semestar-8/IIS/Project/real-time-sign-language-recognition-macedonian/workspace/images/test/b.5c16aac2-d400-11eb-84e0-5cf3709ec7ac.jpg']\n"]}]},{"cell_type":"code","metadata":{"id":"OruLaOHU1KEz","executionInfo":{"status":"ok","timestamp":1631111608401,"user_tz":-120,"elapsed":256,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["import io\n","import os\n","import scipy.misc\n","import numpy as np\n","import six\n","import time\n","import glob\n","from IPython.display import display\n","\n","from six import BytesIO\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageDraw, ImageFont\n","\n","import tensorflow as tf\n","from object_detection.utils import ops as utils_ops\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n","\n","%matplotlib inline\n","\n","\n","def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: a file path (this can be local or on colossus)\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"OOfowlfG05wh","executionInfo":{"status":"ok","timestamp":1631111608806,"user_tz":-120,"elapsed":3,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["def run_inference_for_single_image(image):\n","  image = np.asarray(image)\n","  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","  input_tensor = tf.convert_to_tensor(image)\n","  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","  input_tensor = input_tensor[tf.newaxis,...]\n","\n","  # Run inference\n","  model_fn = detect_fn\n","  output_dict = model_fn(input_tensor)\n","\n","  # All outputs are batches tensors.\n","  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","  # We're only interested in the first num_detections.\n","  num_detections = int(output_dict.pop('num_detections'))\n","  output_dict = {key:value[0, :num_detections].numpy() \n","                 for key,value in output_dict.items()}\n","  output_dict['num_detections'] = num_detections\n","\n","  # detection_classes should be ints.\n","  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n","   \n","  # Handle models with masks:\n","  if 'detection_masks' in output_dict:\n","    # Reframe the the bbox mask to the image size.\n","    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","              output_dict['detection_masks'], output_dict['detection_boxes'],\n","               image.shape[0], image.shape[1])      \n","    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n","                                       tf.uint8)\n","    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n","    \n","  return output_dict"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6XY4nh409_E"},"source":["image_path = imgs[2]\n","image_np = load_image_into_numpy_array(image_path)\n","#print(image_np)\n","input_tensor = np.expand_dims(image_np, 0)\n","start_time = time.time()\n","detections = detect_fn(input_tensor)\n","end_time = time.time()\n","# elapsed.append(end_time - start_time)\n","#print(detections['detection_scores'])\n","\n","plt.rcParams['figure.figsize'] = [42, 21]\n","label_id_offset = 1\n","image_np_with_detections = image_np.copy()\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_detections,\n","      detections['detection_boxes'][0].numpy(),\n","      detections['detection_classes'][0].numpy().astype(np.int32),\n","      detections['detection_scores'][0].numpy(),\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=3,\n","      min_score_thresh=.50,\n","      agnostic_mode=False)\n","plt.subplot(2, 1, 0+1)\n","plt.imshow(image_np_with_detections)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4AcZrAZrPxXj","executionInfo":{"status":"ok","timestamp":1631111642247,"user_tz":-120,"elapsed":250,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["def make_predictions(image_path):\n","  image_np = load_image_into_numpy_array(image_path)\n","  #print(image_np)\n","  input_tensor = np.expand_dims(image_np, 0)\n","  start_time = time.time()\n","  detections = detect_fn(input_tensor)\n","  end_time = time.time()\n","  # elapsed.append(end_time - start_time)\n","  #print(detections['detection_scores'])\n","\n","  plt.rcParams['figure.figsize'] = [42, 21]\n","  label_id_offset = 1\n","  image_np_with_detections = image_np.copy()\n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","        image_np_with_detections,\n","        detections['detection_boxes'][0].numpy(),\n","        detections['detection_classes'][0].numpy().astype(np.int32),\n","        detections['detection_scores'][0].numpy(),\n","        category_index,\n","        use_normalized_coordinates=True,\n","        max_boxes_to_draw=3,\n","        min_score_thresh=.50,\n","        agnostic_mode=False)\n","  plt.subplot(2, 1, 0+1)\n","  plt.imshow(image_np_with_detections)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fj9YcAnsT4B_","executionInfo":{"status":"ok","timestamp":1631111663895,"user_tz":-120,"elapsed":283,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWQrfX5L3YTg"},"source":["## Helper Functions\n","Below are a few helper function to make converting between different image data types and formats. "]},{"cell_type":"code","metadata":{"id":"YgdSqgMb4e8f","executionInfo":{"status":"ok","timestamp":1631111664930,"user_tz":-120,"elapsed":3,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","from PIL import Image as ImagePIL\n","import io\n","import html\n","import time"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjQgNWwe3YTg","executionInfo":{"status":"ok","timestamp":1631111665311,"user_tz":-120,"elapsed":5,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","\n","  image = ImagePIL.open(BytesIO(image_bytes))\n","  (im_width, im_height) = image.size\n","  image_np = np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img, image_np\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-O2nOrV_3YTg"},"source":["## Haar Cascade Classifier\n","For this tutorial we will run a simple object detection algorithm called Haar Cascade on our images and video fetched from our webcam. OpenCV has a pre-trained Haar Cascade face detection model. "]},{"cell_type":"code","metadata":{"id":"gEPkoOIa3YTg","executionInfo":{"status":"ok","timestamp":1631111666042,"user_tz":-120,"elapsed":5,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["# initialize the Haar Cascade face detection model\n","face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aLssfkQB3YTi"},"source":["## Webcam Videos\n","Running code on webcam video is a little more complex than images. We need to start a video stream using our webcam as input. Then we run each frame through our progam (face detection) and create an overlay image that contains bounding box of detection(s). We then overlay the bounding box image back onto the next frame of our video stream.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"NnyJpt7j3YTi","executionInfo":{"status":"ok","timestamp":1631111667580,"user_tz":-120,"elapsed":3,"user":{"displayName":"Risto Trajanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmsREooEqLfzcfpsdoxwY03szCrh3MkoQvlh6VeQ=s64","userId":"05317215598829212050"}}},"source":["# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","  \n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"h57zBGRY3YTj"},"source":["# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","# initialze bounding box to empty\n","bbox = ''\n","count = 0 \n","while True:\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","\n","    # convert JS response to OpenCV Image\n","    img, image_np = js_to_image(js_reply[\"img\"])\n","\n","    \n","    input_tensor = np.expand_dims(image_np, 0)\n","    start_time = time.time()\n","    detections = detect_fn(input_tensor)\n","    output_dict = detections\n","    end_time = time.time()\n","    # elapsed.append(end_time - start_time)\n","    # print(detections['detection_scores'])\n","\n","    plt.rcParams['figure.figsize'] = [42, 21]\n","    label_id_offset = 1\n","    image_np_with_detections = image_np.copy()\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","          image_np_with_detections,\n","          detections['detection_boxes'][0].numpy(),\n","          detections['detection_classes'][0].numpy().astype(np.int32),\n","          detections['detection_scores'][0].numpy(),\n","          category_index,\n","          use_normalized_coordinates=True,\n","          max_boxes_to_draw=3,\n","          min_score_thresh=.50,\n","          agnostic_mode=False)\n","    # print(jpg_as_np)\n","\n","    boxes = np.squeeze(detections['detection_boxes'][0].numpy())\n","    scores = np.squeeze(detections['detection_scores'][0].numpy().astype(np.int32))\n","    print(scores)\n","    #set a min thresh score, say 0.8\n","    min_score_thresh = 0.1\n","    bboxes = boxes[scores > min_score_thresh]\n","\n","    #get image size\n","    im_width, im_height = 480,640\n","    final_box = []\n","    for box in bboxes:\n","        ymin, xmin, ymax, xmax = box\n","        final_box.append([xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height])\n","\n","    # print(final_box)\n","\n","    # create transparent overlay for bounding box\n","    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n","\n","    # grayscale image for face detection\n","    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","\n","    # get face region coordinates\n","    faces = face_cascade.detectMultiScale(gray)\n","    # get face bounding box for overlay\n","    for (x,y,w,h) in faces:\n","      bbox_array = cv2.rectangle(bbox_array,(x,y),(x+w,y+h),(255,0,0),2)\n","\n","    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n","    # convert overlay of bbox into bytes\n","    bbox_bytes = bbox_to_bytes(bbox_array)\n","    # update bbox so next frame gets new overlay\n","    bbox = bbox_bytes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XDD8EdN-3YTj"},"source":["## Hope You Enjoyed!\n","If you enjoyed the tutorial and want to see more videos or tutorials check out my YouTube channel [HERE](https://www.youtube.com/channel/UCrydcKaojc44XnuXrfhlV8Q?sub_confirmation=1)\n","\n","Have a great day!"]},{"cell_type":"code","metadata":{"id":"ocNxYqZoPlFN"},"source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","  data = eval_js('takePhoto({})'.format(quality))\n","  binary = b64decode(data.split(',')[1])\n","  with open(filename, 'wb') as f:\n","    f.write(binary)\n","  return filename"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5tLYBXw4Pk6H"},"source":["#from IPython.display import Image\n","try:\n","  filename = take_photo()\n","  print('Saved to {}'.format(filename))\n","  \n","  # Show the image which was just taken.\n","  make_predictions(filename)\n","except Exception as err:\n","  # Errors will be thrown if the user does not have a webcam or if they do not\n","  # grant the page permission to access it.\n","  print(str(err))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wprNWy3MQp50"},"source":[""],"execution_count":null,"outputs":[]}]}